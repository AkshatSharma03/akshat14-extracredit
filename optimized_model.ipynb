{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud Detection Project\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('CS506 Extra Credit Credit Card Fraud/train.csv')\n",
    "test_df = pd.read_csv('CS506 Extra Credit Credit Card Fraud/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (370703, 24)\n",
      "Test dataset shape: (92676, 23)\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the datasets\n",
    "print(\"Train dataset shape:\", train_df.shape)\n",
    "print(\"Test dataset shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>merchant</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308467</td>\n",
       "      <td>26ad750c2ff71f32631b58913582d70a</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>06:49:39</td>\n",
       "      <td>1704887379</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>188.38</td>\n",
       "      <td>676355457570</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>...</td>\n",
       "      <td>62220</td>\n",
       "      <td>38.5127</td>\n",
       "      <td>-89.9847</td>\n",
       "      <td>95666</td>\n",
       "      <td>Accounting technician</td>\n",
       "      <td>1983-05-26</td>\n",
       "      <td>fraud_Turcotte-Halvorson</td>\n",
       "      <td>39.268874</td>\n",
       "      <td>-89.273447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261578</td>\n",
       "      <td>fea9c1efe3f2b97f27ad0ab5409ec861</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>02:37:50</td>\n",
       "      <td>1704526670</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>102.63</td>\n",
       "      <td>377178373574671</td>\n",
       "      <td>Rhonda</td>\n",
       "      <td>Chavez</td>\n",
       "      <td>...</td>\n",
       "      <td>21784</td>\n",
       "      <td>39.4567</td>\n",
       "      <td>-76.9696</td>\n",
       "      <td>37941</td>\n",
       "      <td>Designer, graphic</td>\n",
       "      <td>1976-12-03</td>\n",
       "      <td>fraud_Schamberger-O'Keefe</td>\n",
       "      <td>39.961495</td>\n",
       "      <td>-76.707640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>2ae350b982be840f3666273e0c2f3a05</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>21:40:21</td>\n",
       "      <td>1705632021</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3599292013370451</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>Khan</td>\n",
       "      <td>...</td>\n",
       "      <td>49735</td>\n",
       "      <td>45.0125</td>\n",
       "      <td>-84.6723</td>\n",
       "      <td>19515</td>\n",
       "      <td>Careers information officer</td>\n",
       "      <td>1999-08-24</td>\n",
       "      <td>fraud_Nicolas, Hills and McGlynn</td>\n",
       "      <td>44.393561</td>\n",
       "      <td>-85.342323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1147639</td>\n",
       "      <td>bbdd8adfc0a34ed0e817f809193c85c0</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>16:20:15</td>\n",
       "      <td>1705872015</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>5.64</td>\n",
       "      <td>3594292572430345</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Reilly</td>\n",
       "      <td>...</td>\n",
       "      <td>44256</td>\n",
       "      <td>41.1404</td>\n",
       "      <td>-81.8584</td>\n",
       "      <td>62039</td>\n",
       "      <td>Merchandiser, retail</td>\n",
       "      <td>1930-02-24</td>\n",
       "      <td>fraud_Cormier LLC</td>\n",
       "      <td>40.283764</td>\n",
       "      <td>-81.639361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314152</td>\n",
       "      <td>fc7756004dc2a9bc450eb894a670b804</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>19:36:26</td>\n",
       "      <td>1705883786</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>97.09</td>\n",
       "      <td>4867547663675548</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Duarte</td>\n",
       "      <td>...</td>\n",
       "      <td>91501</td>\n",
       "      <td>34.1862</td>\n",
       "      <td>-118.3009</td>\n",
       "      <td>106841</td>\n",
       "      <td>Prison officer</td>\n",
       "      <td>1951-10-15</td>\n",
       "      <td>fraud_Kulas Group</td>\n",
       "      <td>35.149704</td>\n",
       "      <td>-118.087440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                         trans_num  trans_date trans_time  \\\n",
       "0   308467  26ad750c2ff71f32631b58913582d70a  2024-01-10   06:49:39   \n",
       "1   261578  fea9c1efe3f2b97f27ad0ab5409ec861  2024-01-06   02:37:50   \n",
       "2      341  2ae350b982be840f3666273e0c2f3a05  2024-01-18   21:40:21   \n",
       "3  1147639  bbdd8adfc0a34ed0e817f809193c85c0  2024-01-21   16:20:15   \n",
       "4   314152  fc7756004dc2a9bc450eb894a670b804  2024-01-21   19:36:26   \n",
       "\n",
       "    unix_time        category     amt            cc_num    first     last  \\\n",
       "0  1704887379        misc_pos  188.38      676355457570   Andrea  Johnson   \n",
       "1  1704526670     grocery_pos  102.63   377178373574671   Rhonda   Chavez   \n",
       "2  1705632021   entertainment    1.62  3599292013370451  Stephen     Khan   \n",
       "3  1705872015  health_fitness    5.64  3594292572430345   Justin   Reilly   \n",
       "4  1705883786  health_fitness   97.09  4867547663675548    Alice   Duarte   \n",
       "\n",
       "   ...    zip      lat      long city_pop                          job  \\\n",
       "0  ...  62220  38.5127  -89.9847    95666        Accounting technician   \n",
       "1  ...  21784  39.4567  -76.9696    37941            Designer, graphic   \n",
       "2  ...  49735  45.0125  -84.6723    19515  Careers information officer   \n",
       "3  ...  44256  41.1404  -81.8584    62039         Merchandiser, retail   \n",
       "4  ...  91501  34.1862 -118.3009   106841               Prison officer   \n",
       "\n",
       "          dob                          merchant  merch_lat  merch_long  \\\n",
       "0  1983-05-26          fraud_Turcotte-Halvorson  39.268874  -89.273447   \n",
       "1  1976-12-03         fraud_Schamberger-O'Keefe  39.961495  -76.707640   \n",
       "2  1999-08-24  fraud_Nicolas, Hills and McGlynn  44.393561  -85.342323   \n",
       "3  1930-02-24                 fraud_Cormier LLC  40.283764  -81.639361   \n",
       "4  1951-10-15                 fraud_Kulas Group  35.149704 -118.087440   \n",
       "\n",
       "  is_fraud  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train dataset:\n",
      "id            0\n",
      "trans_num     0\n",
      "trans_date    0\n",
      "trans_time    0\n",
      "unix_time     0\n",
      "category      0\n",
      "amt           0\n",
      "cc_num        0\n",
      "first         0\n",
      "last          0\n",
      "gender        0\n",
      "street        0\n",
      "city          0\n",
      "state         0\n",
      "zip           0\n",
      "lat           0\n",
      "long          0\n",
      "city_pop      0\n",
      "job           0\n",
      "dob           0\n",
      "merchant      0\n",
      "merch_lat     0\n",
      "merch_long    0\n",
      "is_fraud      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test dataset:\n",
      "id            0\n",
      "trans_num     0\n",
      "trans_date    0\n",
      "trans_time    0\n",
      "unix_time     0\n",
      "category      0\n",
      "amt           0\n",
      "cc_num        0\n",
      "first         0\n",
      "last          0\n",
      "gender        0\n",
      "street        0\n",
      "city          0\n",
      "state         0\n",
      "zip           0\n",
      "lat           0\n",
      "long          0\n",
      "city_pop      0\n",
      "job           0\n",
      "dob           0\n",
      "merchant      0\n",
      "merch_lat     0\n",
      "merch_long    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the distribution of the target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='is_fraud', data=train_df)\n",
    "plt.title('Distribution of Fraud and Non-Fraud Transactions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of fraudulent transactions: 11.41%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of fraudulent transactions\n",
    "fraud_percentage = train_df['is_fraud'].mean() * 100\n",
    "print(f\"Percentage of fraudulent transactions: {fraud_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the relationship between transaction amount and fraud\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='is_fraud', y='amt', data=train_df)\n",
    "plt.title('Transaction Amount vs Fraud')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the relationship between transaction category and fraud\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='category', hue='is_fraud', data=train_df)\n",
    "plt.title('Transaction Category vs Fraud')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite values in train_df: False\n",
      "Infinite values in test_df: False\n"
     ]
    }
   ],
   "source": [
    " # Handle infinite values by focusing only on numeric columns\n",
    "def handle_infinite_values(df):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns  # Select only numeric columns\n",
    "    df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)  # Replace inf with NaN\n",
    "    return df\n",
    "\n",
    "# Apply the function to train and test datasets\n",
    "train_df = handle_infinite_values(train_df)\n",
    "test_df = handle_infinite_values(test_df)\n",
    "\n",
    "# Verify if infinite values have been removed\n",
    "print(\"Infinite values in train_df:\", train_df.select_dtypes(include=[np.number]).apply(np.isinf).values.any())\n",
    "print(\"Infinite values in test_df:\", test_df.select_dtypes(include=[np.number]).apply(np.isinf).values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/rmz3xz_s61dd6zjh0mqy_z2m0000gn/T/ipykernel_29781/882291773.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['trans_hour'] = pd.to_datetime(df['trans_time']).dt.hour\n",
      "/var/folders/cr/rmz3xz_s61dd6zjh0mqy_z2m0000gn/T/ipykernel_29781/882291773.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['trans_hour'] = pd.to_datetime(df['trans_time']).dt.hour\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature engineering with error handling\n",
    "def engineer_features(df):\n",
    "    try:\n",
    "        df['trans_hour'] = pd.to_datetime(df['trans_time']).dt.hour\n",
    "        df['time_since_last'] = df.groupby('cc_num')['unix_time'].diff()\n",
    "        df['trans_freq'] = df.groupby('cc_num')['unix_time'].transform('count') / (\n",
    "            df.groupby('cc_num')['unix_time'].transform('max') - \n",
    "            df.groupby('cc_num')['unix_time'].transform('min')\n",
    "        )\n",
    "        df['avg_amt'] = df.groupby('cc_num')['amt'].transform('mean')\n",
    "        df['amt_to_avg'] = df['amt'] / df['avg_amt']\n",
    "        df['distance'] = np.sqrt((df['lat'] - df['merch_lat'])**2 + (df['long'] - df['merch_long'])**2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature engineering: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = engineer_features(train_df)\n",
    "test_df = engineer_features(test_df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for model training\n",
    "categorical_features = ['category', 'gender', 'state', 'job']\n",
    "numerical_features = ['amt', 'lat', 'long', 'city_pop', 'trans_hour', 'time_since_last', 'trans_freq', 'amt_to_avg', 'distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the feature matrix and target variable\n",
    "X = train_df[categorical_features + numerical_features]\n",
    "y = train_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing steps\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('feature_selection', SelectFromModel(GradientBoostingClassifier(random_state=42))),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=200, max_depth=20, min_samples_split=2, min_samples_leaf=1))\n",
    "])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_pipeline_output(pipeline, X):\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    \n",
    "    # Convert to DataFrame if necessary\n",
    "    if not isinstance(X_transformed, pd.DataFrame):\n",
    "        X_transformed = pd.DataFrame(X_transformed)\n",
    "    \n",
    "    # Validate only numeric columns\n",
    "    numeric_cols = X_transformed.select_dtypes(include=[np.number])\n",
    "    if numeric_cols.isnull().values.any() or np.isinf(numeric_cols).values.any():\n",
    "        raise ValueError(\"Pipeline output contains NaN or infinity.\")\n",
    "    \n",
    "    return X_transformed\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a89d279",
   "metadata": {},
   "source": [
    "# Fraud Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f9cd5",
   "metadata": {},
   "source": [
    "\n",
    "### This notebook demonstrates the process of fraud detection using machine learning.\n",
    "It includes:\n",
    "1. Data Preprocessing\n",
    "2. Feature Engineering\n",
    "3. Model Training and Evaluation\n",
    "4. Prediction and Submission\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49764513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Missing values handled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values for train and test datasets\n",
    "print(\"Handling missing values...\")\n",
    "\n",
    "# Define numeric columns dynamically to exclude 'is_fraud' from test data\n",
    "numeric_cols_train = train_df.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols_test = test_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Impute missing values for numeric columns\n",
    "train_df[numeric_cols_train] = train_df[numeric_cols_train].fillna(train_df[numeric_cols_train].median())\n",
    "test_df[numeric_cols_test] = test_df[numeric_cols_test].fillna(test_df[numeric_cols_test].median())\n",
    "\n",
    "# Handle non-numeric columns\n",
    "non_numeric_cols_train = train_df.select_dtypes(exclude=[np.number]).columns\n",
    "non_numeric_cols_test = test_df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Fill non-numeric columns with \"missing\"\n",
    "train_df[non_numeric_cols_train] = train_df[non_numeric_cols_train].fillna(\"missing\")\n",
    "test_df[non_numeric_cols_test] = test_df[non_numeric_cols_test].fillna(\"missing\")\n",
    "\n",
    "print(\"Missing values handled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3501b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (296562, 28), Validation shape: (74141, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train-validation split\n",
    "X = train_df.drop(columns=['is_fraud', 'id'])\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ec746095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining non-numeric columns in test_df: Index(['trans_num', 'trans_date', 'trans_time', 'category', 'first', 'last',\n",
      "       'gender', 'street', 'city', 'state', 'job', 'dob', 'merchant'],\n",
      "      dtype='object')\n",
      "Processing 'dob' to convert to age...\n",
      "Processing 'city' column...\n",
      "Categorical columns encoded successfully.\n",
      "id                   int64\n",
      "unix_time            int64\n",
      "category             int64\n",
      "amt                float64\n",
      "cc_num               int64\n",
      "gender               int64\n",
      "city                 int64\n",
      "state                int64\n",
      "zip                  int64\n",
      "lat                float64\n",
      "long               float64\n",
      "city_pop             int64\n",
      "job                  int64\n",
      "merch_lat          float64\n",
      "merch_long         float64\n",
      "is_fraud             int64\n",
      "trans_hour           int32\n",
      "time_since_last    float64\n",
      "trans_freq         float64\n",
      "avg_amt            float64\n",
      "amt_to_avg         float64\n",
      "distance           float64\n",
      "age                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Check non-numeric columns before assertion\n",
    "non_numeric_test_cols = test_df.select_dtypes(include=['object']).columns\n",
    "print(\"Remaining non-numeric columns in test_df:\", non_numeric_test_cols)\n",
    "\n",
    "# Drop irrelevant columns (if not already dropped)\n",
    "columns_to_drop = ['trans_num', 'trans_date', 'trans_time', 'first', 'last', 'street', 'merchant']\n",
    "train_df = train_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_df = test_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Process 'dob' if present\n",
    "if 'dob' in train_df.columns and 'dob' in test_df.columns:\n",
    "    print(\"Processing 'dob' to convert to age...\")\n",
    "    for df in [train_df, test_df]:\n",
    "        df['dob'] = pd.to_datetime(df['dob'], errors='coerce')  # Convert to datetime\n",
    "        df['age'] = (pd.Timestamp.now() - df['dob']).dt.days // 365  # Calculate age in years\n",
    "        df.drop(columns=['dob'], inplace=True)  # Drop 'dob' column\n",
    "else:\n",
    "    print(\"'dob' column not found. Skipping age processing.\")\n",
    "\n",
    "# Handle the 'city' column\n",
    "if 'city' in train_df.columns and 'city' in test_df.columns:\n",
    "    print(\"Processing 'city' column...\")\n",
    "    combined_cities = pd.concat([train_df['city'], test_df['city']], axis=0).astype(str).unique()\n",
    "    city_encoder = LabelEncoder()\n",
    "    city_encoder.fit(combined_cities)\n",
    "    \n",
    "    train_df['city'] = city_encoder.transform(train_df['city'].astype(str))\n",
    "    test_df['city'] = city_encoder.transform(test_df['city'].astype(str))\n",
    "else:\n",
    "    print(\"'city' column not found. Skipping city encoding.\")\n",
    "\n",
    "# Encode other categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    # Fit on the union of unique values from both train and test\n",
    "    combined_values = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
    "    label_encoders[col].fit(combined_values)\n",
    "\n",
    "    # Transform train and test datasets\n",
    "    train_df[col] = label_encoders[col].transform(train_df[col].astype(str))\n",
    "    test_df[col] = label_encoders[col].transform(test_df[col].astype(str))\n",
    "\n",
    "# Ensure no non-numeric columns remain\n",
    "non_numeric_test_cols = test_df.select_dtypes(include=['object']).columns\n",
    "if not non_numeric_test_cols.empty:\n",
    "    raise ValueError(f\"Non-numeric columns still present in test_df after encoding: {non_numeric_test_cols}\")\n",
    "\n",
    "print(\"Categorical columns encoded successfully.\")\n",
    "\n",
    "# Check if all features are numeric before training\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# Define feature matrix and target variable\n",
    "X_train = train_df.drop(columns=['is_fraud'], errors='ignore')\n",
    "y_train = train_df['is_fraud']\n",
    "\n",
    "X_test = test_df  # Ensure this matches the columns of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc7c6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align test_features with X_train\n",
    "test_features = test_df.copy()  # Define test_features based on the processed test_df\n",
    "\n",
    "# Ensure test_features has the same columns as X_train\n",
    "missing_in_test = set(X_train.columns) - set(test_features.columns)\n",
    "for col in missing_in_test:\n",
    "    print(f\"Adding missing column '{col}' to test_features with default value 0.\")\n",
    "    test_features[col] = 0\n",
    "\n",
    "extra_in_test = set(test_features.columns) - set(X_train.columns)\n",
    "if extra_in_test:\n",
    "    print(f\"Removing extra columns from test_features: {extra_in_test}\")\n",
    "    test_features = test_features.drop(columns=list(extra_in_test))\n",
    "\n",
    "# Ensure columns are in the same order as X_train\n",
    "test_features = test_features[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83adca",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Importance\n",
    "Analyzing feature importance for better interpretability of the model.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a08121c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is not a LightGBM instance or it has not been fitted.\n"
     ]
    }
   ],
   "source": [
    "# Ensure model is fitted\n",
    "if hasattr(model, \"booster_\"):  # Check if model is LGBMClassifier\n",
    "    # Plot feature importance using the model directly\n",
    "    lgb.plot_importance(model, max_num_features=20, importance_type='gain')\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.show()\n",
    "\n",
    "    # Access Booster object\n",
    "    booster = model.booster_\n",
    "    lgb.plot_importance(booster, max_num_features=20, importance_type='gain')\n",
    "    plt.title('Top 20 Feature Importances (Booster)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The model is not a LightGBM instance or it has not been fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e658f5",
   "metadata": {},
   "source": [
    "### Fix: Handling Missing and Invalid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c29fa822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing inf/-inf with NaN and imputing missing values...\n",
      "Missing and invalid values handled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace infinite values with NaN and handle missing values\n",
    "print(\"Replacing inf/-inf with NaN and imputing missing values...\")\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "train_df.fillna(train_df.median(), inplace=True)\n",
    "test_df.fillna(test_df.median(), inplace=True)\n",
    "\n",
    "print(\"Missing and invalid values handled.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Replace infinite values with NaN\n",
    "test_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill missing values with the median of each column\n",
    "test_features.fillna(test_features.median(), inplace=True)\n",
    "\n",
    "# Check if all problematic values are handled\n",
    "if test_features.isnull().any().any():\n",
    "    raise ValueError(\"test_features still contains NaN values after imputation.\")\n",
    "\n",
    "# Optionally, clip large values (e.g., cap at the 99th percentile)\n",
    "clip_threshold = test_features.quantile(0.99)\n",
    "test_features = test_features.clip(upper=clip_threshold, axis=1)\n",
    "\n",
    "print(\"Test features cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e48d8e1",
   "metadata": {},
   "source": [
    "### Debugging Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for large/infinite values...\n",
      "Preprocessing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/rmz3xz_s61dd6zjh0mqy_z2m0000gn/T/ipykernel_29781/2638875707.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for infinity or extremely large values in X_train and X_test\n",
    "def preprocess_for_large_values(X):\n",
    "    # Replace infinity values with NaN\n",
    "    X.replace([float('inf'), -float('inf')], np.nan, inplace=True)\n",
    "\n",
    "    # Replace NaN with column means\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().any():\n",
    "            X[col].fillna(X[col].mean(), inplace=True)\n",
    "    \n",
    "    # Cap extremely large values if needed (optional)\n",
    "    max_value = 1e10  # Adjust threshold as needed\n",
    "    X = X.clip(upper=max_value)\n",
    "    return X\n",
    "\n",
    "# Preprocess training and test datasets\n",
    "print(\"Preprocessing for large/infinite values...\")\n",
    "X_train = preprocess_for_large_values(X_train)\n",
    "X_test = preprocess_for_large_values(X_test)\n",
    "\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93c80e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model...\n",
      "Model fitting complete.\n",
      "Making predictions on test data...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessors\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Use median for numerical columns\n",
    "    ('scaler', StandardScaler())                   # Scale numerical columns\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Fill missing categories\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))                      # Encode categorical data\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the full pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "print(\"Fitting the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model fitting complete.\")\n",
    "\n",
    "# Predictions\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47f19451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in train_df: Index(['id', 'unix_time', 'category', 'amt', 'cc_num', 'gender', 'city',\n",
      "       'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'merch_lat',\n",
      "       'merch_long', 'is_fraud', 'trans_hour', 'time_since_last', 'trans_freq',\n",
      "       'avg_amt', 'amt_to_avg', 'distance', 'age'],\n",
      "      dtype='object')\n",
      "Available columns in test_df: Index(['id', 'unix_time', 'category', 'amt', 'cc_num', 'gender', 'city',\n",
      "       'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'merch_lat',\n",
      "       'merch_long', 'trans_hour', 'time_since_last', 'trans_freq', 'avg_amt',\n",
      "       'amt_to_avg', 'distance', 'age'],\n",
      "      dtype='object')\n",
      "No time-related column found. Skipping time-based feature engineering.\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Check available columns\n",
    "print(\"Available columns in train_df:\", train_df.columns)\n",
    "print(\"Available columns in test_df:\", test_df.columns)\n",
    "\n",
    "# Attempt to set a time column\n",
    "time_column = None  # Initialize to None\n",
    "possible_time_columns = ['transaction_time', 'timestamp', 'trans_date']  # Common names\n",
    "for col in possible_time_columns:\n",
    "    if col in train_df.columns and col in test_df.columns:\n",
    "        time_column = col\n",
    "        break\n",
    "\n",
    "if time_column:\n",
    "    print(f\"Using '{time_column}' as the time column.\")\n",
    "    \n",
    "    # Add time-based features\n",
    "    print(\"Adding time-based features...\")\n",
    "    train_df['hour'] = pd.to_datetime(train_df[time_column]).dt.hour\n",
    "    test_df['hour'] = pd.to_datetime(test_df[time_column]).dt.hour\n",
    "\n",
    "    train_df['day_of_week'] = pd.to_datetime(train_df[time_column]).dt.dayofweek\n",
    "    test_df['day_of_week'] = pd.to_datetime(test_df[time_column]).dt.dayofweek\n",
    "\n",
    "    train_df['is_weekend'] = (train_df['day_of_week'] >= 5).astype(int)\n",
    "    test_df['is_weekend'] = (test_df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "    # Calculate time since last transaction for each user\n",
    "    user_column = 'user_id'  # Adjust if necessary\n",
    "    if user_column in train_df.columns:\n",
    "        print(\"Calculating time since last transaction...\")\n",
    "        train_df['time_since_last'] = train_df.groupby(user_column)[time_column].diff().fillna(0)\n",
    "        test_df['time_since_last'] = test_df.groupby(user_column)[time_column].diff().fillna(0)\n",
    "else:\n",
    "    print(\"No time-related column found. Skipping time-based feature engineering.\")\n",
    "\n",
    "# Add aggregated features\n",
    "user_column = 'user_id'\n",
    "transaction_amt_column = 'transaction_amt'\n",
    "if user_column in train_df.columns and transaction_amt_column in train_df.columns:\n",
    "    print(\"Adding aggregated features...\")\n",
    "    train_df['avg_transaction_amt'] = train_df.groupby(user_column)[transaction_amt_column].transform('mean')\n",
    "    test_df['avg_transaction_amt'] = test_df.groupby(user_column)[transaction_amt_column].transform('mean')\n",
    "\n",
    "    train_df['transaction_ratio'] = train_df[transaction_amt_column] / train_df['avg_transaction_amt']\n",
    "    test_df['transaction_ratio'] = test_df[transaction_amt_column] / test_df['avg_transaction_amt']\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c36462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:02,056] A new study created in memory with name: no-name-838a84c6-16f7-4a34-8f83-d0ae0e0a45da\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995779\tvalid_1's auc: 0.99574\n",
      "[20]\ttraining's auc: 0.998302\tvalid_1's auc: 0.99801\n",
      "[30]\ttraining's auc: 0.999282\tvalid_1's auc: 0.998785\n",
      "[40]\ttraining's auc: 0.999685\tvalid_1's auc: 0.999204\n",
      "[50]\ttraining's auc: 0.999842\tvalid_1's auc: 0.999301\n",
      "[60]\ttraining's auc: 0.999913\tvalid_1's auc: 0.999368\n",
      "[70]\ttraining's auc: 0.999961\tvalid_1's auc: 0.999402\n",
      "[80]\ttraining's auc: 0.999984\tvalid_1's auc: 0.999402\n",
      "[90]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999418\n",
      "[100]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999428\n",
      "[110]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999443\n",
      "[120]\ttraining's auc: 1\tvalid_1's auc: 0.999437\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:06,200] Trial 0 finished with value: 0.9994453353290746 and parameters: {'num_leaves': 106, 'learning_rate': 0.15035556648028364, 'max_depth': 38, 'min_child_samples': 72, 'n_estimators': 192}. Best is trial 0 with value: 0.9994453353290746.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992967\tvalid_1's auc: 0.992983\n",
      "[20]\ttraining's auc: 0.995619\tvalid_1's auc: 0.995647\n",
      "[30]\ttraining's auc: 0.997098\tvalid_1's auc: 0.996942\n",
      "[40]\ttraining's auc: 0.997795\tvalid_1's auc: 0.997585\n",
      "[50]\ttraining's auc: 0.998479\tvalid_1's auc: 0.998219\n",
      "[60]\ttraining's auc: 0.998914\tvalid_1's auc: 0.998497\n",
      "[70]\ttraining's auc: 0.99923\tvalid_1's auc: 0.99876\n",
      "[80]\ttraining's auc: 0.999478\tvalid_1's auc: 0.998999\n",
      "[90]\ttraining's auc: 0.999629\tvalid_1's auc: 0.9991\n",
      "[100]\ttraining's auc: 0.999737\tvalid_1's auc: 0.999226\n",
      "[110]\ttraining's auc: 0.999813\tvalid_1's auc: 0.999316\n",
      "[120]\ttraining's auc: 0.999865\tvalid_1's auc: 0.999345\n",
      "[130]\ttraining's auc: 0.999902\tvalid_1's auc: 0.999368\n",
      "[140]\ttraining's auc: 0.999929\tvalid_1's auc: 0.999383\n",
      "[150]\ttraining's auc: 0.999951\tvalid_1's auc: 0.999397\n",
      "[160]\ttraining's auc: 0.999967\tvalid_1's auc: 0.999405\n",
      "[170]\ttraining's auc: 0.999977\tvalid_1's auc: 0.999411\n",
      "[180]\ttraining's auc: 0.999985\tvalid_1's auc: 0.999421\n",
      "[190]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999433\n",
      "[200]\ttraining's auc: 0.999993\tvalid_1's auc: 0.999436\n",
      "[210]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999442\n",
      "[220]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999441\n",
      "[230]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999451\n",
      "[240]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999453\n",
      "[250]\ttraining's auc: 1\tvalid_1's auc: 0.999465\n",
      "[260]\ttraining's auc: 1\tvalid_1's auc: 0.999469\n",
      "[270]\ttraining's auc: 1\tvalid_1's auc: 0.999473\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's auc: 1\tvalid_1's auc: 0.999475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:14,970] Trial 1 finished with value: 0.9994747390158861 and parameters: {'num_leaves': 123, 'learning_rate': 0.060143644023999646, 'max_depth': 42, 'min_child_samples': 91, 'n_estimators': 667}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995809\tvalid_1's auc: 0.995916\n",
      "[20]\ttraining's auc: 0.998681\tvalid_1's auc: 0.998277\n",
      "[30]\ttraining's auc: 0.999405\tvalid_1's auc: 0.99906\n",
      "[40]\ttraining's auc: 0.999698\tvalid_1's auc: 0.999339\n",
      "[50]\ttraining's auc: 0.999853\tvalid_1's auc: 0.999363\n",
      "[60]\ttraining's auc: 0.999917\tvalid_1's auc: 0.999413\n",
      "[70]\ttraining's auc: 0.999953\tvalid_1's auc: 0.999421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:17,208] Trial 2 finished with value: 0.9994274805430269 and parameters: {'num_leaves': 72, 'learning_rate': 0.1956988701769783, 'max_depth': 16, 'min_child_samples': 48, 'n_estimators': 622}. Best is trial 1 with value: 0.9994747390158861.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.99995\tvalid_1's auc: 0.999427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.968032\tvalid_1's auc: 0.968364\n",
      "[20]\ttraining's auc: 0.988929\tvalid_1's auc: 0.989179\n",
      "[30]\ttraining's auc: 0.990491\tvalid_1's auc: 0.990757\n",
      "[40]\ttraining's auc: 0.991662\tvalid_1's auc: 0.992016\n",
      "[50]\ttraining's auc: 0.992628\tvalid_1's auc: 0.992987\n",
      "[60]\ttraining's auc: 0.993377\tvalid_1's auc: 0.993672\n",
      "[70]\ttraining's auc: 0.994069\tvalid_1's auc: 0.994362\n",
      "[80]\ttraining's auc: 0.994906\tvalid_1's auc: 0.995123\n",
      "[90]\ttraining's auc: 0.995421\tvalid_1's auc: 0.995578\n",
      "[100]\ttraining's auc: 0.995755\tvalid_1's auc: 0.995868\n",
      "[110]\ttraining's auc: 0.996166\tvalid_1's auc: 0.996245\n",
      "[120]\ttraining's auc: 0.996879\tvalid_1's auc: 0.996911\n",
      "[130]\ttraining's auc: 0.997466\tvalid_1's auc: 0.997493\n",
      "[140]\ttraining's auc: 0.997999\tvalid_1's auc: 0.997994\n",
      "[150]\ttraining's auc: 0.998308\tvalid_1's auc: 0.998289\n",
      "[160]\ttraining's auc: 0.998486\tvalid_1's auc: 0.998444\n",
      "[170]\ttraining's auc: 0.998617\tvalid_1's auc: 0.998553\n",
      "[180]\ttraining's auc: 0.998747\tvalid_1's auc: 0.998668\n",
      "[190]\ttraining's auc: 0.998872\tvalid_1's auc: 0.998791\n",
      "[200]\ttraining's auc: 0.998983\tvalid_1's auc: 0.998887\n",
      "[210]\ttraining's auc: 0.999059\tvalid_1's auc: 0.998958\n",
      "[220]\ttraining's auc: 0.999147\tvalid_1's auc: 0.999046\n",
      "[230]\ttraining's auc: 0.999233\tvalid_1's auc: 0.999116\n",
      "[240]\ttraining's auc: 0.999293\tvalid_1's auc: 0.999166\n",
      "[250]\ttraining's auc: 0.999341\tvalid_1's auc: 0.999197\n",
      "[260]\ttraining's auc: 0.999372\tvalid_1's auc: 0.999219\n",
      "[270]\ttraining's auc: 0.999404\tvalid_1's auc: 0.999243\n",
      "[280]\ttraining's auc: 0.99944\tvalid_1's auc: 0.999269\n",
      "[290]\ttraining's auc: 0.999467\tvalid_1's auc: 0.999289\n",
      "[300]\ttraining's auc: 0.999488\tvalid_1's auc: 0.999298\n",
      "[310]\ttraining's auc: 0.99951\tvalid_1's auc: 0.999306\n",
      "[320]\ttraining's auc: 0.999531\tvalid_1's auc: 0.999313\n",
      "[330]\ttraining's auc: 0.999551\tvalid_1's auc: 0.999318\n",
      "[340]\ttraining's auc: 0.99957\tvalid_1's auc: 0.999328\n",
      "[350]\ttraining's auc: 0.999584\tvalid_1's auc: 0.999337\n",
      "[360]\ttraining's auc: 0.9996\tvalid_1's auc: 0.999341\n",
      "[370]\ttraining's auc: 0.999613\tvalid_1's auc: 0.999342\n",
      "Early stopping, best iteration is:\n",
      "[362]\ttraining's auc: 0.999603\tvalid_1's auc: 0.999344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:25,518] Trial 3 finished with value: 0.9993436261787886 and parameters: {'num_leaves': 29, 'learning_rate': 0.0383540367843551, 'max_depth': 8, 'min_child_samples': 58, 'n_estimators': 440}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.996809\tvalid_1's auc: 0.996687\n",
      "[20]\ttraining's auc: 0.998493\tvalid_1's auc: 0.998131\n",
      "[30]\ttraining's auc: 0.999269\tvalid_1's auc: 0.998781\n",
      "[40]\ttraining's auc: 0.999658\tvalid_1's auc: 0.999142\n",
      "[50]\ttraining's auc: 0.999837\tvalid_1's auc: 0.999294\n",
      "[60]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999347\n",
      "[70]\ttraining's auc: 0.999971\tvalid_1's auc: 0.999354\n",
      "[80]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999376\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.99998\tvalid_1's auc: 0.999383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:28,580] Trial 4 finished with value: 0.9993829719782864 and parameters: {'num_leaves': 129, 'learning_rate': 0.16612416030670285, 'max_depth': 12, 'min_child_samples': 86, 'n_estimators': 546}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttraining's auc: 0.976525\tvalid_1's auc: 0.977176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\ttraining's auc: 0.983442\tvalid_1's auc: 0.983608\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\ttraining's auc: 0.987148\tvalid_1's auc: 0.987607\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\ttraining's auc: 0.98856\tvalid_1's auc: 0.988947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's auc: 0.992755\tvalid_1's auc: 0.992929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\ttraining's auc: 0.994718\tvalid_1's auc: 0.994874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\ttraining's auc: 0.995354\tvalid_1's auc: 0.995504\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\ttraining's auc: 0.996652\tvalid_1's auc: 0.996689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\ttraining's auc: 0.997052\tvalid_1's auc: 0.997018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.997423\tvalid_1's auc: 0.997351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[110]\ttraining's auc: 0.997843\tvalid_1's auc: 0.997732\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\ttraining's auc: 0.998039\tvalid_1's auc: 0.997915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[130]\ttraining's auc: 0.99825\tvalid_1's auc: 0.99812\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[140]\ttraining's auc: 0.998487\tvalid_1's auc: 0.998353\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttraining's auc: 0.998598\tvalid_1's auc: 0.99847\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[160]\ttraining's auc: 0.998692\tvalid_1's auc: 0.998562\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[170]\ttraining's auc: 0.998755\tvalid_1's auc: 0.998616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[180]\ttraining's auc: 0.998831\tvalid_1's auc: 0.998697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[190]\ttraining's auc: 0.998898\tvalid_1's auc: 0.998761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttraining's auc: 0.998939\tvalid_1's auc: 0.998788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[210]\ttraining's auc: 0.999029\tvalid_1's auc: 0.998891\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[220]\ttraining's auc: 0.999065\tvalid_1's auc: 0.998921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[230]\ttraining's auc: 0.999128\tvalid_1's auc: 0.998994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[240]\ttraining's auc: 0.999187\tvalid_1's auc: 0.999059\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[250]\ttraining's auc: 0.999203\tvalid_1's auc: 0.99907\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[260]\ttraining's auc: 0.99923\tvalid_1's auc: 0.999076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[270]\ttraining's auc: 0.999273\tvalid_1's auc: 0.999116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[280]\ttraining's auc: 0.999296\tvalid_1's auc: 0.999126\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[290]\ttraining's auc: 0.999314\tvalid_1's auc: 0.999141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\ttraining's auc: 0.999334\tvalid_1's auc: 0.999158\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[310]\ttraining's auc: 0.999355\tvalid_1's auc: 0.999175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[320]\ttraining's auc: 0.999381\tvalid_1's auc: 0.999179\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[330]\ttraining's auc: 0.999403\tvalid_1's auc: 0.999196\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[340]\ttraining's auc: 0.999432\tvalid_1's auc: 0.999222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[350]\ttraining's auc: 0.999445\tvalid_1's auc: 0.999225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[360]\ttraining's auc: 0.999463\tvalid_1's auc: 0.999234\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:36,070] Trial 5 finished with value: 0.9992373873484625 and parameters: {'num_leaves': 107, 'learning_rate': 0.17799646340759287, 'max_depth': 3, 'min_child_samples': 57, 'n_estimators': 804}. Best is trial 1 with value: 0.9994747390158861.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's auc: 0.999455\tvalid_1's auc: 0.999237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995237\tvalid_1's auc: 0.995308\n",
      "[20]\ttraining's auc: 0.998047\tvalid_1's auc: 0.997903\n",
      "[30]\ttraining's auc: 0.999141\tvalid_1's auc: 0.998889\n",
      "[40]\ttraining's auc: 0.999601\tvalid_1's auc: 0.999295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:37,572] Trial 6 finished with value: 0.999305574191444 and parameters: {'num_leaves': 57, 'learning_rate': 0.18922283951309607, 'max_depth': 23, 'min_child_samples': 60, 'n_estimators': 785}. Best is trial 1 with value: 0.9994747390158861.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's auc: 0.999741\tvalid_1's auc: 0.999287\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.999662\tvalid_1's auc: 0.999306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99212\tvalid_1's auc: 0.99198\n",
      "[20]\ttraining's auc: 0.994912\tvalid_1's auc: 0.994951\n",
      "[30]\ttraining's auc: 0.996285\tvalid_1's auc: 0.996365\n",
      "[40]\ttraining's auc: 0.997341\tvalid_1's auc: 0.997203\n",
      "[50]\ttraining's auc: 0.998013\tvalid_1's auc: 0.997761\n",
      "[60]\ttraining's auc: 0.998631\tvalid_1's auc: 0.998335\n",
      "[70]\ttraining's auc: 0.998959\tvalid_1's auc: 0.998572\n",
      "[80]\ttraining's auc: 0.999216\tvalid_1's auc: 0.998785\n",
      "[90]\ttraining's auc: 0.999461\tvalid_1's auc: 0.999045\n",
      "[100]\ttraining's auc: 0.999594\tvalid_1's auc: 0.999151\n",
      "[110]\ttraining's auc: 0.999691\tvalid_1's auc: 0.99921\n",
      "[120]\ttraining's auc: 0.999762\tvalid_1's auc: 0.999249\n",
      "[130]\ttraining's auc: 0.999818\tvalid_1's auc: 0.999305\n",
      "[140]\ttraining's auc: 0.999865\tvalid_1's auc: 0.999332\n",
      "[150]\ttraining's auc: 0.999897\tvalid_1's auc: 0.999356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[148]\ttraining's auc: 0.999891\tvalid_1's auc: 0.999358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:42,269] Trial 7 finished with value: 0.9993582085385082 and parameters: {'num_leaves': 112, 'learning_rate': 0.05262472270789838, 'max_depth': 39, 'min_child_samples': 64, 'n_estimators': 151}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.970172\tvalid_1's auc: 0.970347\n",
      "[20]\ttraining's auc: 0.990191\tvalid_1's auc: 0.99015\n",
      "[30]\ttraining's auc: 0.993028\tvalid_1's auc: 0.993206\n",
      "[40]\ttraining's auc: 0.993805\tvalid_1's auc: 0.993953\n",
      "[50]\ttraining's auc: 0.994417\tvalid_1's auc: 0.994511\n",
      "[60]\ttraining's auc: 0.994932\tvalid_1's auc: 0.99507\n",
      "[70]\ttraining's auc: 0.995503\tvalid_1's auc: 0.99561\n",
      "[80]\ttraining's auc: 0.996203\tvalid_1's auc: 0.996288\n",
      "[90]\ttraining's auc: 0.996725\tvalid_1's auc: 0.996773\n",
      "[100]\ttraining's auc: 0.997095\tvalid_1's auc: 0.997096\n",
      "[110]\ttraining's auc: 0.997451\tvalid_1's auc: 0.997388\n",
      "[120]\ttraining's auc: 0.997697\tvalid_1's auc: 0.99761\n",
      "[130]\ttraining's auc: 0.997912\tvalid_1's auc: 0.997781\n",
      "[140]\ttraining's auc: 0.998227\tvalid_1's auc: 0.998105\n",
      "[150]\ttraining's auc: 0.998451\tvalid_1's auc: 0.998308\n",
      "[160]\ttraining's auc: 0.998665\tvalid_1's auc: 0.998499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[162]\ttraining's auc: 0.998712\tvalid_1's auc: 0.998548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:46,192] Trial 8 finished with value: 0.998547606245286 and parameters: {'num_leaves': 50, 'learning_rate': 0.029966138048393393, 'max_depth': 48, 'min_child_samples': 53, 'n_estimators': 162}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995661\tvalid_1's auc: 0.995675\n",
      "[20]\ttraining's auc: 0.998251\tvalid_1's auc: 0.998056\n",
      "[30]\ttraining's auc: 0.99925\tvalid_1's auc: 0.998869\n",
      "[40]\ttraining's auc: 0.999629\tvalid_1's auc: 0.99922\n",
      "[50]\ttraining's auc: 0.999785\tvalid_1's auc: 0.999334\n",
      "[60]\ttraining's auc: 0.99987\tvalid_1's auc: 0.999399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:48,744] Trial 9 finished with value: 0.9994040385571501 and parameters: {'num_leaves': 77, 'learning_rate': 0.17091053599227715, 'max_depth': 36, 'min_child_samples': 97, 'n_estimators': 846}. Best is trial 1 with value: 0.9994747390158861.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\ttraining's auc: 0.999919\tvalid_1's auc: 0.999393\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.999884\tvalid_1's auc: 0.999404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995139\tvalid_1's auc: 0.995091\n",
      "[20]\ttraining's auc: 0.997306\tvalid_1's auc: 0.997208\n",
      "[30]\ttraining's auc: 0.998424\tvalid_1's auc: 0.998014\n",
      "[40]\ttraining's auc: 0.999138\tvalid_1's auc: 0.998574\n",
      "[50]\ttraining's auc: 0.999532\tvalid_1's auc: 0.998858\n",
      "[60]\ttraining's auc: 0.999719\tvalid_1's auc: 0.999062\n",
      "[70]\ttraining's auc: 0.999837\tvalid_1's auc: 0.999148\n",
      "[80]\ttraining's auc: 0.99991\tvalid_1's auc: 0.999188\n",
      "[90]\ttraining's auc: 0.999954\tvalid_1's auc: 0.999268\n",
      "[100]\ttraining's auc: 0.999977\tvalid_1's auc: 0.99931\n",
      "[110]\ttraining's auc: 0.999989\tvalid_1's auc: 0.999359\n",
      "[120]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999377\n",
      "[130]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999387\n",
      "[140]\ttraining's auc: 1\tvalid_1's auc: 0.999391\n",
      "[150]\ttraining's auc: 1\tvalid_1's auc: 0.999393\n",
      "[160]\ttraining's auc: 1\tvalid_1's auc: 0.9994\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's auc: 1\tvalid_1's auc: 0.999401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:36:54,973] Trial 10 finished with value: 0.9994014420161508 and parameters: {'num_leaves': 146, 'learning_rate': 0.0851547664372585, 'max_depth': 50, 'min_child_samples': 23, 'n_estimators': 984}. Best is trial 1 with value: 0.9994747390158861.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995462\tvalid_1's auc: 0.995459\n",
      "[20]\ttraining's auc: 0.997846\tvalid_1's auc: 0.997637\n",
      "[30]\ttraining's auc: 0.998936\tvalid_1's auc: 0.998643\n",
      "[40]\ttraining's auc: 0.999485\tvalid_1's auc: 0.999077\n",
      "[50]\ttraining's auc: 0.999735\tvalid_1's auc: 0.999293\n",
      "[60]\ttraining's auc: 0.99986\tvalid_1's auc: 0.999374\n",
      "[70]\ttraining's auc: 0.99992\tvalid_1's auc: 0.999386\n",
      "[80]\ttraining's auc: 0.999954\tvalid_1's auc: 0.999409\n",
      "[90]\ttraining's auc: 0.999976\tvalid_1's auc: 0.99942\n",
      "[100]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999423\n",
      "[110]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999443\n",
      "[120]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999452\n",
      "[130]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999461\n",
      "[140]\ttraining's auc: 1\tvalid_1's auc: 0.999475\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's auc: 1\tvalid_1's auc: 0.999477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:00,365] Trial 11 finished with value: 0.9994773266401924 and parameters: {'num_leaves': 104, 'learning_rate': 0.12882707998920118, 'max_depth': 34, 'min_child_samples': 81, 'n_estimators': 335}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995885\tvalid_1's auc: 0.995845\n",
      "[20]\ttraining's auc: 0.99789\tvalid_1's auc: 0.997635\n",
      "[30]\ttraining's auc: 0.998982\tvalid_1's auc: 0.998474\n",
      "[40]\ttraining's auc: 0.999523\tvalid_1's auc: 0.998979\n",
      "[50]\ttraining's auc: 0.999741\tvalid_1's auc: 0.999131\n",
      "[60]\ttraining's auc: 0.999866\tvalid_1's auc: 0.999232\n",
      "[70]\ttraining's auc: 0.999929\tvalid_1's auc: 0.99929\n",
      "[80]\ttraining's auc: 0.999969\tvalid_1's auc: 0.999328\n",
      "[90]\ttraining's auc: 0.999984\tvalid_1's auc: 0.999331\n",
      "[100]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999357\n",
      "[110]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999386\n",
      "[120]\ttraining's auc: 1\tvalid_1's auc: 0.9994\n",
      "[130]\ttraining's auc: 1\tvalid_1's auc: 0.999416\n",
      "[140]\ttraining's auc: 1\tvalid_1's auc: 0.999426\n",
      "[150]\ttraining's auc: 1\tvalid_1's auc: 0.999433\n",
      "[160]\ttraining's auc: 1\tvalid_1's auc: 0.999434\n",
      "[170]\ttraining's auc: 1\tvalid_1's auc: 0.999441\n",
      "[180]\ttraining's auc: 1\tvalid_1's auc: 0.99944\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's auc: 1\tvalid_1's auc: 0.999445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:08,026] Trial 12 finished with value: 0.9994446523103916 and parameters: {'num_leaves': 127, 'learning_rate': 0.12376033714405126, 'max_depth': 30, 'min_child_samples': 83, 'n_estimators': 368}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992537\tvalid_1's auc: 0.992479\n",
      "[20]\ttraining's auc: 0.995751\tvalid_1's auc: 0.995745\n",
      "[30]\ttraining's auc: 0.997681\tvalid_1's auc: 0.997494\n",
      "[40]\ttraining's auc: 0.998504\tvalid_1's auc: 0.998258\n",
      "[50]\ttraining's auc: 0.998995\tvalid_1's auc: 0.998632\n",
      "[60]\ttraining's auc: 0.999388\tvalid_1's auc: 0.999019\n",
      "[70]\ttraining's auc: 0.999586\tvalid_1's auc: 0.999157\n",
      "[80]\ttraining's auc: 0.999718\tvalid_1's auc: 0.999282\n",
      "[90]\ttraining's auc: 0.999806\tvalid_1's auc: 0.999335\n",
      "[100]\ttraining's auc: 0.99986\tvalid_1's auc: 0.999372\n",
      "[110]\ttraining's auc: 0.999893\tvalid_1's auc: 0.999378\n",
      "[120]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999396\n",
      "[130]\ttraining's auc: 0.999947\tvalid_1's auc: 0.999412\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's auc: 0.999943\tvalid_1's auc: 0.999413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:12,492] Trial 13 finished with value: 0.9994130604671198 and parameters: {'num_leaves': 93, 'learning_rate': 0.0869013895280035, 'max_depth': 29, 'min_child_samples': 97, 'n_estimators': 326}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99635\tvalid_1's auc: 0.995963\n",
      "[20]\ttraining's auc: 0.998203\tvalid_1's auc: 0.997783\n",
      "[30]\ttraining's auc: 0.999133\tvalid_1's auc: 0.998534\n",
      "[40]\ttraining's auc: 0.999605\tvalid_1's auc: 0.998992\n",
      "[50]\ttraining's auc: 0.999813\tvalid_1's auc: 0.999156\n",
      "[60]\ttraining's auc: 0.999915\tvalid_1's auc: 0.999302\n",
      "[70]\ttraining's auc: 0.99997\tvalid_1's auc: 0.99935\n",
      "[80]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999383\n",
      "[90]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999392\n",
      "[100]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:16,399] Trial 14 finished with value: 0.9994141768370823 and parameters: {'num_leaves': 146, 'learning_rate': 0.12632328429356918, 'max_depth': 43, 'min_child_samples': 81, 'n_estimators': 612}. Best is trial 11 with value: 0.9994773266401924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992682\tvalid_1's auc: 0.992525\n",
      "[20]\ttraining's auc: 0.995715\tvalid_1's auc: 0.995775\n",
      "[30]\ttraining's auc: 0.997282\tvalid_1's auc: 0.997171\n",
      "[40]\ttraining's auc: 0.998115\tvalid_1's auc: 0.997846\n",
      "[50]\ttraining's auc: 0.998771\tvalid_1's auc: 0.998386\n",
      "[60]\ttraining's auc: 0.999162\tvalid_1's auc: 0.998678\n",
      "[70]\ttraining's auc: 0.999423\tvalid_1's auc: 0.998832\n",
      "[80]\ttraining's auc: 0.999627\tvalid_1's auc: 0.999072\n",
      "[90]\ttraining's auc: 0.999735\tvalid_1's auc: 0.99913\n",
      "[100]\ttraining's auc: 0.99982\tvalid_1's auc: 0.999178\n",
      "[110]\ttraining's auc: 0.999879\tvalid_1's auc: 0.999222\n",
      "[120]\ttraining's auc: 0.999917\tvalid_1's auc: 0.999278\n",
      "[130]\ttraining's auc: 0.999947\tvalid_1's auc: 0.999309\n",
      "[140]\ttraining's auc: 0.999966\tvalid_1's auc: 0.999346\n",
      "[150]\ttraining's auc: 0.999977\tvalid_1's auc: 0.999351\n",
      "[160]\ttraining's auc: 0.999985\tvalid_1's auc: 0.999356\n",
      "[170]\ttraining's auc: 0.99999\tvalid_1's auc: 0.99936\n",
      "[180]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999376\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's auc: 0.999993\tvalid_1's auc: 0.999379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:22,360] Trial 15 finished with value: 0.999379269767356 and parameters: {'num_leaves': 124, 'learning_rate': 0.0637896100746467, 'max_depth': 21, 'min_child_samples': 26, 'n_estimators': 483}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.994807\tvalid_1's auc: 0.994908\n",
      "[20]\ttraining's auc: 0.996782\tvalid_1's auc: 0.996832\n",
      "[30]\ttraining's auc: 0.998351\tvalid_1's auc: 0.998182\n",
      "[40]\ttraining's auc: 0.999046\tvalid_1's auc: 0.99868\n",
      "[50]\ttraining's auc: 0.999484\tvalid_1's auc: 0.999087\n",
      "[60]\ttraining's auc: 0.999685\tvalid_1's auc: 0.999235\n",
      "[70]\ttraining's auc: 0.9998\tvalid_1's auc: 0.99929\n",
      "[80]\ttraining's auc: 0.999875\tvalid_1's auc: 0.999345\n",
      "[90]\ttraining's auc: 0.999916\tvalid_1's auc: 0.99936\n",
      "[100]\ttraining's auc: 0.999944\tvalid_1's auc: 0.999372\n",
      "[110]\ttraining's auc: 0.999964\tvalid_1's auc: 0.999389\n",
      "[120]\ttraining's auc: 0.999981\tvalid_1's auc: 0.999403\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's auc: 0.999974\tvalid_1's auc: 0.999411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:26,118] Trial 16 finished with value: 0.9994106333432873 and parameters: {'num_leaves': 91, 'learning_rate': 0.10674550523022741, 'max_depth': 33, 'min_child_samples': 40, 'n_estimators': 671}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.993118\tvalid_1's auc: 0.993085\n",
      "[20]\ttraining's auc: 0.99629\tvalid_1's auc: 0.996291\n",
      "[30]\ttraining's auc: 0.997696\tvalid_1's auc: 0.997397\n",
      "[40]\ttraining's auc: 0.998464\tvalid_1's auc: 0.998125\n",
      "[50]\ttraining's auc: 0.998986\tvalid_1's auc: 0.998551\n",
      "[60]\ttraining's auc: 0.999355\tvalid_1's auc: 0.998876\n",
      "[70]\ttraining's auc: 0.999589\tvalid_1's auc: 0.999079\n",
      "[80]\ttraining's auc: 0.999741\tvalid_1's auc: 0.999227\n",
      "[90]\ttraining's auc: 0.999831\tvalid_1's auc: 0.999307\n",
      "[100]\ttraining's auc: 0.999885\tvalid_1's auc: 0.999339\n",
      "[110]\ttraining's auc: 0.999921\tvalid_1's auc: 0.999348\n",
      "[120]\ttraining's auc: 0.999949\tvalid_1's auc: 0.999374\n",
      "[130]\ttraining's auc: 0.999968\tvalid_1's auc: 0.999382\n",
      "[140]\ttraining's auc: 0.999979\tvalid_1's auc: 0.999388\n",
      "[150]\ttraining's auc: 0.999987\tvalid_1's auc: 0.999397\n",
      "[160]\ttraining's auc: 0.999993\tvalid_1's auc: 0.9994\n",
      "[170]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999409\n",
      "[180]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999415\n",
      "[190]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999423\n",
      "[200]\ttraining's auc: 1\tvalid_1's auc: 0.99943\n",
      "[210]\ttraining's auc: 1\tvalid_1's auc: 0.999437\n",
      "[220]\ttraining's auc: 1\tvalid_1's auc: 0.999442\n",
      "[230]\ttraining's auc: 1\tvalid_1's auc: 0.999442\n",
      "[240]\ttraining's auc: 1\tvalid_1's auc: 0.999442\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's auc: 1\tvalid_1's auc: 0.999446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:34,817] Trial 17 finished with value: 0.9994461752815545 and parameters: {'num_leaves': 116, 'learning_rate': 0.07683712573045569, 'max_depth': 44, 'min_child_samples': 73, 'n_estimators': 300}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995337\tvalid_1's auc: 0.99532\n",
      "[20]\ttraining's auc: 0.997631\tvalid_1's auc: 0.997378\n",
      "[30]\ttraining's auc: 0.998988\tvalid_1's auc: 0.998649\n",
      "[40]\ttraining's auc: 0.999492\tvalid_1's auc: 0.99905\n",
      "[50]\ttraining's auc: 0.999741\tvalid_1's auc: 0.999293\n",
      "[60]\ttraining's auc: 0.999855\tvalid_1's auc: 0.999375\n",
      "[70]\ttraining's auc: 0.999916\tvalid_1's auc: 0.999387\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.999898\tvalid_1's auc: 0.999396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:37:37,946] Trial 18 finished with value: 0.9993958993997868 and parameters: {'num_leaves': 95, 'learning_rate': 0.13983241512492292, 'max_depth': 43, 'min_child_samples': 100, 'n_estimators': 432}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99124\tvalid_1's auc: 0.990967\n",
      "[20]\ttraining's auc: 0.992181\tvalid_1's auc: 0.991789\n",
      "[30]\ttraining's auc: 0.992983\tvalid_1's auc: 0.992732\n",
      "[40]\ttraining's auc: 0.993224\tvalid_1's auc: 0.992988\n",
      "[50]\ttraining's auc: 0.993594\tvalid_1's auc: 0.993564\n",
      "[60]\ttraining's auc: 0.994739\tvalid_1's auc: 0.994606\n",
      "[70]\ttraining's auc: 0.994998\tvalid_1's auc: 0.994873\n",
      "[80]\ttraining's auc: 0.995158\tvalid_1's auc: 0.995009\n",
      "[90]\ttraining's auc: 0.995767\tvalid_1's auc: 0.995725\n",
      "[100]\ttraining's auc: 0.996168\tvalid_1's auc: 0.996079\n",
      "[110]\ttraining's auc: 0.996343\tvalid_1's auc: 0.996235\n",
      "[120]\ttraining's auc: 0.996632\tvalid_1's auc: 0.9965\n",
      "[130]\ttraining's auc: 0.997007\tvalid_1's auc: 0.996816\n",
      "[140]\ttraining's auc: 0.997208\tvalid_1's auc: 0.997039\n",
      "[150]\ttraining's auc: 0.997345\tvalid_1's auc: 0.997155\n",
      "[160]\ttraining's auc: 0.997481\tvalid_1's auc: 0.997252\n",
      "[170]\ttraining's auc: 0.997586\tvalid_1's auc: 0.997331\n",
      "[180]\ttraining's auc: 0.997732\tvalid_1's auc: 0.997431\n",
      "[190]\ttraining's auc: 0.997879\tvalid_1's auc: 0.99758\n",
      "[200]\ttraining's auc: 0.997975\tvalid_1's auc: 0.997665\n",
      "[210]\ttraining's auc: 0.998163\tvalid_1's auc: 0.997841\n",
      "[220]\ttraining's auc: 0.998275\tvalid_1's auc: 0.997941\n",
      "[230]\ttraining's auc: 0.998369\tvalid_1's auc: 0.998017\n",
      "[240]\ttraining's auc: 0.998501\tvalid_1's auc: 0.998104\n",
      "[250]\ttraining's auc: 0.998616\tvalid_1's auc: 0.998168\n",
      "[260]\ttraining's auc: 0.998697\tvalid_1's auc: 0.998242\n",
      "[270]\ttraining's auc: 0.998768\tvalid_1's auc: 0.998321\n",
      "[280]\ttraining's auc: 0.998862\tvalid_1's auc: 0.998395\n",
      "[290]\ttraining's auc: 0.998928\tvalid_1's auc: 0.998431\n",
      "[300]\ttraining's auc: 0.999001\tvalid_1's auc: 0.998478\n",
      "[310]\ttraining's auc: 0.999067\tvalid_1's auc: 0.998553\n",
      "[320]\ttraining's auc: 0.999131\tvalid_1's auc: 0.998601\n",
      "[330]\ttraining's auc: 0.99918\tvalid_1's auc: 0.99863\n",
      "[340]\ttraining's auc: 0.99923\tvalid_1's auc: 0.998675\n",
      "[350]\ttraining's auc: 0.99928\tvalid_1's auc: 0.998719\n",
      "[360]\ttraining's auc: 0.999328\tvalid_1's auc: 0.998761\n",
      "[370]\ttraining's auc: 0.999375\tvalid_1's auc: 0.998797\n",
      "[380]\ttraining's auc: 0.999421\tvalid_1's auc: 0.99886\n",
      "[390]\ttraining's auc: 0.999462\tvalid_1's auc: 0.998882\n",
      "[400]\ttraining's auc: 0.999498\tvalid_1's auc: 0.998913\n",
      "[410]\ttraining's auc: 0.999532\tvalid_1's auc: 0.99894\n",
      "[420]\ttraining's auc: 0.999562\tvalid_1's auc: 0.998959\n",
      "[430]\ttraining's auc: 0.999594\tvalid_1's auc: 0.998988\n",
      "[440]\ttraining's auc: 0.999624\tvalid_1's auc: 0.999022\n",
      "[450]\ttraining's auc: 0.99965\tvalid_1's auc: 0.999044\n",
      "[460]\ttraining's auc: 0.999674\tvalid_1's auc: 0.999067\n",
      "[470]\ttraining's auc: 0.999701\tvalid_1's auc: 0.999097\n",
      "[480]\ttraining's auc: 0.999726\tvalid_1's auc: 0.999134\n",
      "[490]\ttraining's auc: 0.999748\tvalid_1's auc: 0.999168\n",
      "[500]\ttraining's auc: 0.999768\tvalid_1's auc: 0.999205\n",
      "[510]\ttraining's auc: 0.999786\tvalid_1's auc: 0.999237\n",
      "[520]\ttraining's auc: 0.999802\tvalid_1's auc: 0.99926\n",
      "[530]\ttraining's auc: 0.999815\tvalid_1's auc: 0.999279\n",
      "[540]\ttraining's auc: 0.999827\tvalid_1's auc: 0.999294\n",
      "[550]\ttraining's auc: 0.999841\tvalid_1's auc: 0.999301\n",
      "[560]\ttraining's auc: 0.999851\tvalid_1's auc: 0.99931\n",
      "[570]\ttraining's auc: 0.999861\tvalid_1's auc: 0.999318\n",
      "[580]\ttraining's auc: 0.999871\tvalid_1's auc: 0.999325\n",
      "[590]\ttraining's auc: 0.99988\tvalid_1's auc: 0.999332\n",
      "[600]\ttraining's auc: 0.999889\tvalid_1's auc: 0.999339\n",
      "[610]\ttraining's auc: 0.999897\tvalid_1's auc: 0.999343\n",
      "[620]\ttraining's auc: 0.999905\tvalid_1's auc: 0.999347\n",
      "[630]\ttraining's auc: 0.999912\tvalid_1's auc: 0.99935\n",
      "[640]\ttraining's auc: 0.999919\tvalid_1's auc: 0.999353\n",
      "[650]\ttraining's auc: 0.999925\tvalid_1's auc: 0.999357\n",
      "[660]\ttraining's auc: 0.999931\tvalid_1's auc: 0.999359\n",
      "[670]\ttraining's auc: 0.999935\tvalid_1's auc: 0.999361\n",
      "[680]\ttraining's auc: 0.99994\tvalid_1's auc: 0.999364\n",
      "[690]\ttraining's auc: 0.999945\tvalid_1's auc: 0.999367\n",
      "[700]\ttraining's auc: 0.999949\tvalid_1's auc: 0.999375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[701]\ttraining's auc: 0.999949\tvalid_1's auc: 0.999376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:08,826] Trial 19 finished with value: 0.9993760954246508 and parameters: {'num_leaves': 138, 'learning_rate': 0.011995451707124516, 'max_depth': 25, 'min_child_samples': 91, 'n_estimators': 701}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.993988\tvalid_1's auc: 0.994084\n",
      "[20]\ttraining's auc: 0.995761\tvalid_1's auc: 0.995809\n",
      "[30]\ttraining's auc: 0.997764\tvalid_1's auc: 0.997615\n",
      "[40]\ttraining's auc: 0.998605\tvalid_1's auc: 0.998359\n",
      "[50]\ttraining's auc: 0.999138\tvalid_1's auc: 0.998885\n",
      "[60]\ttraining's auc: 0.999436\tvalid_1's auc: 0.999169\n",
      "[70]\ttraining's auc: 0.999602\tvalid_1's auc: 0.999286\n",
      "[80]\ttraining's auc: 0.99971\tvalid_1's auc: 0.99935\n",
      "[90]\ttraining's auc: 0.999773\tvalid_1's auc: 0.99936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:12,697] Trial 20 finished with value: 0.9993616343319559 and parameters: {'num_leaves': 65, 'learning_rate': 0.10311055905324995, 'max_depth': 34, 'min_child_samples': 72, 'n_estimators': 278}. Best is trial 11 with value: 0.9994773266401924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.99975\tvalid_1's auc: 0.999362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992606\tvalid_1's auc: 0.992469\n",
      "[20]\ttraining's auc: 0.995774\tvalid_1's auc: 0.995808\n",
      "[30]\ttraining's auc: 0.997262\tvalid_1's auc: 0.997132\n",
      "[40]\ttraining's auc: 0.998163\tvalid_1's auc: 0.997883\n",
      "[50]\ttraining's auc: 0.998787\tvalid_1's auc: 0.998442\n",
      "[60]\ttraining's auc: 0.999173\tvalid_1's auc: 0.998763\n",
      "[70]\ttraining's auc: 0.999447\tvalid_1's auc: 0.999003\n",
      "[80]\ttraining's auc: 0.999633\tvalid_1's auc: 0.999166\n",
      "[90]\ttraining's auc: 0.999738\tvalid_1's auc: 0.999235\n",
      "[100]\ttraining's auc: 0.999812\tvalid_1's auc: 0.999301\n",
      "[110]\ttraining's auc: 0.999868\tvalid_1's auc: 0.999359\n",
      "[120]\ttraining's auc: 0.999911\tvalid_1's auc: 0.999376\n",
      "[130]\ttraining's auc: 0.999941\tvalid_1's auc: 0.999386\n",
      "[140]\ttraining's auc: 0.999959\tvalid_1's auc: 0.999405\n",
      "[150]\ttraining's auc: 0.999973\tvalid_1's auc: 0.999416\n",
      "[160]\ttraining's auc: 0.999981\tvalid_1's auc: 0.999423\n",
      "[170]\ttraining's auc: 0.999988\tvalid_1's auc: 0.999427\n",
      "[180]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999431\n",
      "[190]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999437\n",
      "[200]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999444\n",
      "[210]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999454\n",
      "[220]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999457\n",
      "[230]\ttraining's auc: 1\tvalid_1's auc: 0.999457\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:20,457] Trial 21 finished with value: 0.9994605240239179 and parameters: {'num_leaves': 115, 'learning_rate': 0.06730623524159146, 'max_depth': 44, 'min_child_samples': 74, 'n_estimators': 237}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992029\tvalid_1's auc: 0.991909\n",
      "[20]\ttraining's auc: 0.995238\tvalid_1's auc: 0.995335\n",
      "[30]\ttraining's auc: 0.996523\tvalid_1's auc: 0.996524\n",
      "[40]\ttraining's auc: 0.997627\tvalid_1's auc: 0.997373\n",
      "[50]\ttraining's auc: 0.998373\tvalid_1's auc: 0.998158\n",
      "[60]\ttraining's auc: 0.998768\tvalid_1's auc: 0.998481\n",
      "[70]\ttraining's auc: 0.999124\tvalid_1's auc: 0.998738\n",
      "[80]\ttraining's auc: 0.999432\tvalid_1's auc: 0.999055\n",
      "[90]\ttraining's auc: 0.999573\tvalid_1's auc: 0.999142\n",
      "[100]\ttraining's auc: 0.999682\tvalid_1's auc: 0.999238\n",
      "[110]\ttraining's auc: 0.999763\tvalid_1's auc: 0.999312\n",
      "[120]\ttraining's auc: 0.999818\tvalid_1's auc: 0.999352\n",
      "[130]\ttraining's auc: 0.999858\tvalid_1's auc: 0.999381\n",
      "[140]\ttraining's auc: 0.999892\tvalid_1's auc: 0.999389\n",
      "[150]\ttraining's auc: 0.999915\tvalid_1's auc: 0.999395\n",
      "[160]\ttraining's auc: 0.999939\tvalid_1's auc: 0.999402\n",
      "[170]\ttraining's auc: 0.999953\tvalid_1's auc: 0.999407\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's auc: 0.999949\tvalid_1's auc: 0.99941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:26,297] Trial 22 finished with value: 0.9994100983417076 and parameters: {'num_leaves': 103, 'learning_rate': 0.06118936251977516, 'max_depth': 40, 'min_child_samples': 79, 'n_estimators': 240}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992541\tvalid_1's auc: 0.9926\n",
      "[20]\ttraining's auc: 0.994717\tvalid_1's auc: 0.99473\n",
      "[30]\ttraining's auc: 0.995931\tvalid_1's auc: 0.995897\n",
      "[40]\ttraining's auc: 0.997068\tvalid_1's auc: 0.997008\n",
      "[50]\ttraining's auc: 0.997731\tvalid_1's auc: 0.997494\n",
      "[60]\ttraining's auc: 0.998136\tvalid_1's auc: 0.997831\n",
      "[70]\ttraining's auc: 0.998569\tvalid_1's auc: 0.998294\n",
      "[80]\ttraining's auc: 0.998905\tvalid_1's auc: 0.998565\n",
      "[90]\ttraining's auc: 0.99916\tvalid_1's auc: 0.998715\n",
      "[100]\ttraining's auc: 0.99936\tvalid_1's auc: 0.998876\n",
      "[110]\ttraining's auc: 0.999523\tvalid_1's auc: 0.999037\n",
      "[120]\ttraining's auc: 0.999622\tvalid_1's auc: 0.999116\n",
      "[130]\ttraining's auc: 0.999701\tvalid_1's auc: 0.999171\n",
      "[140]\ttraining's auc: 0.999769\tvalid_1's auc: 0.999234\n",
      "[150]\ttraining's auc: 0.999823\tvalid_1's auc: 0.999265\n",
      "[160]\ttraining's auc: 0.99986\tvalid_1's auc: 0.999304\n",
      "[170]\ttraining's auc: 0.99989\tvalid_1's auc: 0.999331\n",
      "[180]\ttraining's auc: 0.999915\tvalid_1's auc: 0.999353\n",
      "[190]\ttraining's auc: 0.999933\tvalid_1's auc: 0.99937\n",
      "[200]\ttraining's auc: 0.999948\tvalid_1's auc: 0.999388\n",
      "[210]\ttraining's auc: 0.999959\tvalid_1's auc: 0.999391\n",
      "[220]\ttraining's auc: 0.999968\tvalid_1's auc: 0.999402\n",
      "[230]\ttraining's auc: 0.999976\tvalid_1's auc: 0.999415\n",
      "[240]\ttraining's auc: 0.999982\tvalid_1's auc: 0.999419\n",
      "[250]\ttraining's auc: 0.999987\tvalid_1's auc: 0.999425\n",
      "[260]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999435\n",
      "[270]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999444\n",
      "[280]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999452\n",
      "[290]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999452\n",
      "[300]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999456\n",
      "[310]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999462\n",
      "[320]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999466\n",
      "[330]\ttraining's auc: 0.999999\tvalid_1's auc: 0.99947\n",
      "[340]\ttraining's auc: 1\tvalid_1's auc: 0.999474\n",
      "[350]\ttraining's auc: 1\tvalid_1's auc: 0.999476\n",
      "Early stopping, best iteration is:\n",
      "[348]\ttraining's auc: 1\tvalid_1's auc: 0.999477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:44,164] Trial 23 finished with value: 0.999476955705764 and parameters: {'num_leaves': 123, 'learning_rate': 0.044188164234331695, 'max_depth': 46, 'min_child_samples': 67, 'n_estimators': 374}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.993071\tvalid_1's auc: 0.992832\n",
      "[20]\ttraining's auc: 0.994997\tvalid_1's auc: 0.994888\n",
      "[30]\ttraining's auc: 0.996051\tvalid_1's auc: 0.995969\n",
      "[40]\ttraining's auc: 0.996995\tvalid_1's auc: 0.996799\n",
      "[50]\ttraining's auc: 0.997546\tvalid_1's auc: 0.997392\n",
      "[60]\ttraining's auc: 0.997931\tvalid_1's auc: 0.997583\n",
      "[70]\ttraining's auc: 0.998439\tvalid_1's auc: 0.998005\n",
      "[80]\ttraining's auc: 0.998781\tvalid_1's auc: 0.998304\n",
      "[90]\ttraining's auc: 0.99903\tvalid_1's auc: 0.998511\n",
      "[100]\ttraining's auc: 0.999229\tvalid_1's auc: 0.998677\n",
      "[110]\ttraining's auc: 0.999417\tvalid_1's auc: 0.998887\n",
      "[120]\ttraining's auc: 0.999544\tvalid_1's auc: 0.998969\n",
      "[130]\ttraining's auc: 0.999646\tvalid_1's auc: 0.999063\n",
      "[140]\ttraining's auc: 0.999746\tvalid_1's auc: 0.999229\n",
      "[150]\ttraining's auc: 0.999802\tvalid_1's auc: 0.999296\n",
      "[160]\ttraining's auc: 0.999846\tvalid_1's auc: 0.99932\n",
      "[170]\ttraining's auc: 0.999881\tvalid_1's auc: 0.999345\n",
      "[180]\ttraining's auc: 0.999908\tvalid_1's auc: 0.999364\n",
      "[190]\ttraining's auc: 0.999929\tvalid_1's auc: 0.999375\n",
      "[200]\ttraining's auc: 0.999948\tvalid_1's auc: 0.999382\n",
      "[210]\ttraining's auc: 0.99996\tvalid_1's auc: 0.999392\n",
      "[220]\ttraining's auc: 0.99997\tvalid_1's auc: 0.999401\n",
      "[230]\ttraining's auc: 0.999977\tvalid_1's auc: 0.999408\n",
      "[240]\ttraining's auc: 0.999982\tvalid_1's auc: 0.999417\n",
      "[250]\ttraining's auc: 0.999987\tvalid_1's auc: 0.999424\n",
      "[260]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999429\n",
      "[270]\ttraining's auc: 0.999993\tvalid_1's auc: 0.999441\n",
      "[280]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999446\n",
      "[290]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999454\n",
      "[300]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999459\n",
      "[310]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999461\n",
      "[320]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999463\n",
      "[330]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999462\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:56,216] Trial 24 finished with value: 0.9994644420188186 and parameters: {'num_leaves': 136, 'learning_rate': 0.04140875661419504, 'max_depth': 47, 'min_child_samples': 89, 'n_estimators': 395}. Best is trial 11 with value: 0.9994773266401924.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.989823\tvalid_1's auc: 0.989715\n",
      "[20]\ttraining's auc: 0.99076\tvalid_1's auc: 0.990575\n",
      "[30]\ttraining's auc: 0.992583\tvalid_1's auc: 0.992685\n",
      "[40]\ttraining's auc: 0.992927\tvalid_1's auc: 0.992951\n",
      "[50]\ttraining's auc: 0.993313\tvalid_1's auc: 0.993527\n",
      "[60]\ttraining's auc: 0.993483\tvalid_1's auc: 0.993665\n",
      "[70]\ttraining's auc: 0.994778\tvalid_1's auc: 0.994776\n",
      "[80]\ttraining's auc: 0.995379\tvalid_1's auc: 0.995451\n",
      "[90]\ttraining's auc: 0.995698\tvalid_1's auc: 0.995716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:38:59,311] Trial 25 finished with value: 0.9958959270914687 and parameters: {'num_leaves': 121, 'learning_rate': 0.013321320876387883, 'max_depth': 33, 'min_child_samples': 68, 'n_estimators': 100}. Best is trial 11 with value: 0.9994773266401924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.995845\tvalid_1's auc: 0.995896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.995845\tvalid_1's auc: 0.995896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.994398\tvalid_1's auc: 0.99427\n",
      "[20]\ttraining's auc: 0.996331\tvalid_1's auc: 0.996349\n",
      "[30]\ttraining's auc: 0.998093\tvalid_1's auc: 0.997801\n",
      "[40]\ttraining's auc: 0.998828\tvalid_1's auc: 0.998444\n",
      "[50]\ttraining's auc: 0.999383\tvalid_1's auc: 0.998932\n",
      "[60]\ttraining's auc: 0.999623\tvalid_1's auc: 0.999063\n",
      "[70]\ttraining's auc: 0.999769\tvalid_1's auc: 0.999248\n",
      "[80]\ttraining's auc: 0.999848\tvalid_1's auc: 0.9993\n",
      "[90]\ttraining's auc: 0.999895\tvalid_1's auc: 0.999342\n",
      "[100]\ttraining's auc: 0.999935\tvalid_1's auc: 0.999366\n",
      "[110]\ttraining's auc: 0.999954\tvalid_1's auc: 0.99939\n",
      "[120]\ttraining's auc: 0.999971\tvalid_1's auc: 0.999404\n",
      "[130]\ttraining's auc: 0.999983\tvalid_1's auc: 0.999412\n",
      "[140]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999428\n",
      "[150]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999441\n",
      "[160]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999447\n",
      "[170]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999461\n",
      "[180]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999469\n",
      "[190]\ttraining's auc: 1\tvalid_1's auc: 0.999472\n",
      "[200]\ttraining's auc: 1\tvalid_1's auc: 0.999477\n",
      "[210]\ttraining's auc: 1\tvalid_1's auc: 0.999483\n",
      "[220]\ttraining's auc: 1\tvalid_1's auc: 0.99949\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's auc: 1\tvalid_1's auc: 0.999491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:09,490] Trial 26 finished with value: 0.9994909941472111 and parameters: {'num_leaves': 84, 'learning_rate': 0.10168818622107392, 'max_depth': 40, 'min_child_samples': 10, 'n_estimators': 533}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99484\tvalid_1's auc: 0.994994\n",
      "[20]\ttraining's auc: 0.996577\tvalid_1's auc: 0.996607\n",
      "[30]\ttraining's auc: 0.998269\tvalid_1's auc: 0.998048\n",
      "[40]\ttraining's auc: 0.99903\tvalid_1's auc: 0.998662\n",
      "[50]\ttraining's auc: 0.999464\tvalid_1's auc: 0.99903\n",
      "[60]\ttraining's auc: 0.999672\tvalid_1's auc: 0.999192\n",
      "[70]\ttraining's auc: 0.999806\tvalid_1's auc: 0.999309\n",
      "[80]\ttraining's auc: 0.999877\tvalid_1's auc: 0.999367\n",
      "[90]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999394\n",
      "[100]\ttraining's auc: 0.999952\tvalid_1's auc: 0.999419\n",
      "[110]\ttraining's auc: 0.999973\tvalid_1's auc: 0.999421\n",
      "[120]\ttraining's auc: 0.999985\tvalid_1's auc: 0.999431\n",
      "[130]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999443\n",
      "[140]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999451\n",
      "[150]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999461\n",
      "[160]\ttraining's auc: 0.999999\tvalid_1's auc: 0.99947\n",
      "[170]\ttraining's auc: 1\tvalid_1's auc: 0.999473\n",
      "[180]\ttraining's auc: 1\tvalid_1's auc: 0.999472\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's auc: 1\tvalid_1's auc: 0.999475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:16,217] Trial 27 finished with value: 0.9994752882841743 and parameters: {'num_leaves': 87, 'learning_rate': 0.10668565747757236, 'max_depth': 30, 'min_child_samples': 16, 'n_estimators': 519}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995378\tvalid_1's auc: 0.995509\n",
      "[20]\ttraining's auc: 0.997803\tvalid_1's auc: 0.997713\n",
      "[30]\ttraining's auc: 0.998916\tvalid_1's auc: 0.998617\n",
      "[40]\ttraining's auc: 0.999501\tvalid_1's auc: 0.999148\n",
      "[50]\ttraining's auc: 0.999732\tvalid_1's auc: 0.999351\n",
      "[60]\ttraining's auc: 0.999836\tvalid_1's auc: 0.999368\n",
      "[70]\ttraining's auc: 0.9999\tvalid_1's auc: 0.999393\n",
      "[80]\ttraining's auc: 0.999947\tvalid_1's auc: 0.999416\n",
      "[90]\ttraining's auc: 0.99997\tvalid_1's auc: 0.999437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:19,249] Trial 28 finished with value: 0.9994367788704792 and parameters: {'num_leaves': 76, 'learning_rate': 0.15031805300697745, 'max_depth': 47, 'min_child_samples': 39, 'n_estimators': 352}. Best is trial 26 with value: 0.9994909941472111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's auc: 0.999969\tvalid_1's auc: 0.999437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995363\tvalid_1's auc: 0.995475\n",
      "[20]\ttraining's auc: 0.997643\tvalid_1's auc: 0.997373\n",
      "[30]\ttraining's auc: 0.998772\tvalid_1's auc: 0.998407\n",
      "[40]\ttraining's auc: 0.999368\tvalid_1's auc: 0.998918\n",
      "[50]\ttraining's auc: 0.999656\tvalid_1's auc: 0.999153\n",
      "[60]\ttraining's auc: 0.999818\tvalid_1's auc: 0.999258\n",
      "[70]\ttraining's auc: 0.999896\tvalid_1's auc: 0.999317\n",
      "[80]\ttraining's auc: 0.999941\tvalid_1's auc: 0.999365\n",
      "[90]\ttraining's auc: 0.999965\tvalid_1's auc: 0.999391\n",
      "[100]\ttraining's auc: 0.999982\tvalid_1's auc: 0.999407\n",
      "[110]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999424\n",
      "[120]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999422\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's auc: 0.999993\tvalid_1's auc: 0.999425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:23,570] Trial 29 finished with value: 0.9994245701344343 and parameters: {'num_leaves': 101, 'learning_rate': 0.11972038020061562, 'max_depth': 37, 'min_child_samples': 45, 'n_estimators': 474}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.991695\tvalid_1's auc: 0.99196\n",
      "[20]\ttraining's auc: 0.994445\tvalid_1's auc: 0.994658\n",
      "[30]\ttraining's auc: 0.996092\tvalid_1's auc: 0.996232\n",
      "[40]\ttraining's auc: 0.997465\tvalid_1's auc: 0.997382\n",
      "[50]\ttraining's auc: 0.998134\tvalid_1's auc: 0.997988\n",
      "[60]\ttraining's auc: 0.998846\tvalid_1's auc: 0.998655\n",
      "[70]\ttraining's auc: 0.999168\tvalid_1's auc: 0.998966\n",
      "[80]\ttraining's auc: 0.999426\tvalid_1's auc: 0.999155\n",
      "[90]\ttraining's auc: 0.999542\tvalid_1's auc: 0.999242\n",
      "[100]\ttraining's auc: 0.999629\tvalid_1's auc: 0.999291\n",
      "[110]\ttraining's auc: 0.999698\tvalid_1's auc: 0.999318\n",
      "[120]\ttraining's auc: 0.999749\tvalid_1's auc: 0.99933\n",
      "[130]\ttraining's auc: 0.999783\tvalid_1's auc: 0.999347\n",
      "[140]\ttraining's auc: 0.999811\tvalid_1's auc: 0.999354\n",
      "[150]\ttraining's auc: 0.999843\tvalid_1's auc: 0.999358\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's auc: 0.999837\tvalid_1's auc: 0.999362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:27,783] Trial 30 finished with value: 0.9993621194000546 and parameters: {'num_leaves': 40, 'learning_rate': 0.09300864719554176, 'max_depth': 37, 'min_child_samples': 10, 'n_estimators': 569}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.994772\tvalid_1's auc: 0.994927\n",
      "[20]\ttraining's auc: 0.996448\tvalid_1's auc: 0.996524\n",
      "[30]\ttraining's auc: 0.998301\tvalid_1's auc: 0.998009\n",
      "[40]\ttraining's auc: 0.999015\tvalid_1's auc: 0.998541\n",
      "[50]\ttraining's auc: 0.9995\tvalid_1's auc: 0.998999\n",
      "[60]\ttraining's auc: 0.9997\tvalid_1's auc: 0.99913\n",
      "[70]\ttraining's auc: 0.999803\tvalid_1's auc: 0.99926\n",
      "[80]\ttraining's auc: 0.999869\tvalid_1's auc: 0.999295\n",
      "[90]\ttraining's auc: 0.999917\tvalid_1's auc: 0.999351\n",
      "[100]\ttraining's auc: 0.999946\tvalid_1's auc: 0.999379\n",
      "[110]\ttraining's auc: 0.999969\tvalid_1's auc: 0.999383\n",
      "[120]\ttraining's auc: 0.99998\tvalid_1's auc: 0.999398\n",
      "[130]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999411\n",
      "[140]\ttraining's auc: 0.999995\tvalid_1's auc: 0.999425\n",
      "[150]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999446\n",
      "[160]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999448\n",
      "[170]\ttraining's auc: 1\tvalid_1's auc: 0.999451\n",
      "[180]\ttraining's auc: 1\tvalid_1's auc: 0.999452\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's auc: 1\tvalid_1's auc: 0.999454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:33,665] Trial 31 finished with value: 0.9994536724370225 and parameters: {'num_leaves': 85, 'learning_rate': 0.10644710441521861, 'max_depth': 32, 'min_child_samples': 12, 'n_estimators': 531}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995252\tvalid_1's auc: 0.995243\n",
      "[20]\ttraining's auc: 0.997892\tvalid_1's auc: 0.997618\n",
      "[30]\ttraining's auc: 0.998973\tvalid_1's auc: 0.998582\n",
      "[40]\ttraining's auc: 0.999485\tvalid_1's auc: 0.999055\n",
      "[50]\ttraining's auc: 0.999734\tvalid_1's auc: 0.999259\n",
      "[60]\ttraining's auc: 0.999847\tvalid_1's auc: 0.999296\n",
      "[70]\ttraining's auc: 0.99992\tvalid_1's auc: 0.999378\n",
      "[80]\ttraining's auc: 0.999955\tvalid_1's auc: 0.999392\n",
      "[90]\ttraining's auc: 0.999979\tvalid_1's auc: 0.999393\n",
      "[100]\ttraining's auc: 0.99999\tvalid_1's auc: 0.999411\n",
      "[110]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999421\n",
      "[120]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999429\n",
      "[130]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999431\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:37,764] Trial 32 finished with value: 0.9994363027190736 and parameters: {'num_leaves': 85, 'learning_rate': 0.13835467472883967, 'max_depth': 28, 'min_child_samples': 18, 'n_estimators': 499}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.994171\tvalid_1's auc: 0.994358\n",
      "[20]\ttraining's auc: 0.996473\tvalid_1's auc: 0.996382\n",
      "[30]\ttraining's auc: 0.998182\tvalid_1's auc: 0.99796\n",
      "[40]\ttraining's auc: 0.998906\tvalid_1's auc: 0.998609\n",
      "[50]\ttraining's auc: 0.999336\tvalid_1's auc: 0.998991\n",
      "[60]\ttraining's auc: 0.999603\tvalid_1's auc: 0.99925\n",
      "[70]\ttraining's auc: 0.999742\tvalid_1's auc: 0.999351\n",
      "[80]\ttraining's auc: 0.999817\tvalid_1's auc: 0.999363\n",
      "[90]\ttraining's auc: 0.999871\tvalid_1's auc: 0.99939\n",
      "[100]\ttraining's auc: 0.999913\tvalid_1's auc: 0.999407\n",
      "[110]\ttraining's auc: 0.999937\tvalid_1's auc: 0.999405\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.999926\tvalid_1's auc: 0.999408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:41,275] Trial 33 finished with value: 0.9994076480344735 and parameters: {'num_leaves': 67, 'learning_rate': 0.11564095199195179, 'max_depth': 40, 'min_child_samples': 28, 'n_estimators': 418}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99548\tvalid_1's auc: 0.995559\n",
      "[20]\ttraining's auc: 0.997973\tvalid_1's auc: 0.997737\n",
      "[30]\ttraining's auc: 0.999203\tvalid_1's auc: 0.998655\n",
      "[40]\ttraining's auc: 0.999615\tvalid_1's auc: 0.999128\n",
      "[50]\ttraining's auc: 0.999796\tvalid_1's auc: 0.999231\n",
      "[60]\ttraining's auc: 0.999914\tvalid_1's auc: 0.999276\n",
      "[70]\ttraining's auc: 0.999959\tvalid_1's auc: 0.999317\n",
      "[80]\ttraining's auc: 0.999981\tvalid_1's auc: 0.999359\n",
      "[90]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999365\n",
      "[100]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999363\n",
      "[110]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999376\n",
      "[120]\ttraining's auc: 1\tvalid_1's auc: 0.999406\n",
      "[130]\ttraining's auc: 1\tvalid_1's auc: 0.999407\n",
      "[140]\ttraining's auc: 1\tvalid_1's auc: 0.999425\n",
      "[150]\ttraining's auc: 1\tvalid_1's auc: 0.999434\n",
      "[160]\ttraining's auc: 1\tvalid_1's auc: 0.999431\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 1\tvalid_1's auc: 0.999437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:47,289] Trial 34 finished with value: 0.9994372282718061 and parameters: {'num_leaves': 97, 'learning_rate': 0.14012306527494048, 'max_depth': 35, 'min_child_samples': 17, 'n_estimators': 579}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.99565\tvalid_1's auc: 0.995733\n",
      "[20]\ttraining's auc: 0.997924\tvalid_1's auc: 0.997716\n",
      "[30]\ttraining's auc: 0.999015\tvalid_1's auc: 0.998622\n",
      "[40]\ttraining's auc: 0.999503\tvalid_1's auc: 0.999076\n",
      "[50]\ttraining's auc: 0.999742\tvalid_1's auc: 0.999292\n",
      "[60]\ttraining's auc: 0.999867\tvalid_1's auc: 0.999341\n",
      "[70]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999371\n",
      "[80]\ttraining's auc: 0.999964\tvalid_1's auc: 0.999394\n",
      "[90]\ttraining's auc: 0.999982\tvalid_1's auc: 0.99941\n",
      "[100]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999419\n",
      "[110]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999427\n",
      "[120]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999432\n",
      "[130]\ttraining's auc: 1\tvalid_1's auc: 0.999433\n",
      "[140]\ttraining's auc: 1\tvalid_1's auc: 0.999438\n",
      "[150]\ttraining's auc: 1\tvalid_1's auc: 0.999445\n",
      "[160]\ttraining's auc: 1\tvalid_1's auc: 0.999451\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttraining's auc: 1\tvalid_1's auc: 0.999455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:52,794] Trial 35 finished with value: 0.9994545819397077 and parameters: {'num_leaves': 80, 'learning_rate': 0.15280019960399963, 'max_depth': 19, 'min_child_samples': 30, 'n_estimators': 451}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.994956\tvalid_1's auc: 0.995044\n",
      "[20]\ttraining's auc: 0.996785\tvalid_1's auc: 0.996807\n",
      "[30]\ttraining's auc: 0.99841\tvalid_1's auc: 0.9981\n",
      "[40]\ttraining's auc: 0.999149\tvalid_1's auc: 0.998686\n",
      "[50]\ttraining's auc: 0.99953\tvalid_1's auc: 0.999058\n",
      "[60]\ttraining's auc: 0.999714\tvalid_1's auc: 0.999191\n",
      "[70]\ttraining's auc: 0.999823\tvalid_1's auc: 0.999283\n",
      "[80]\ttraining's auc: 0.999896\tvalid_1's auc: 0.999333\n",
      "[90]\ttraining's auc: 0.999939\tvalid_1's auc: 0.999373\n",
      "[100]\ttraining's auc: 0.999963\tvalid_1's auc: 0.999394\n",
      "[110]\ttraining's auc: 0.999979\tvalid_1's auc: 0.999397\n",
      "[120]\ttraining's auc: 0.999989\tvalid_1's auc: 0.999405\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's auc: 0.999989\tvalid_1's auc: 0.999409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:39:57,142] Trial 36 finished with value: 0.9994087037709238 and parameters: {'num_leaves': 108, 'learning_rate': 0.09872744291877258, 'max_depth': 25, 'min_child_samples': 35, 'n_estimators': 527}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992067\tvalid_1's auc: 0.991939\n",
      "[20]\ttraining's auc: 0.995619\tvalid_1's auc: 0.995697\n",
      "[30]\ttraining's auc: 0.996721\tvalid_1's auc: 0.996558\n",
      "[40]\ttraining's auc: 0.99819\tvalid_1's auc: 0.998006\n",
      "[50]\ttraining's auc: 0.998793\tvalid_1's auc: 0.998496\n",
      "[60]\ttraining's auc: 0.999162\tvalid_1's auc: 0.998805\n",
      "[70]\ttraining's auc: 0.999426\tvalid_1's auc: 0.99901\n",
      "[80]\ttraining's auc: 0.999619\tvalid_1's auc: 0.999217\n",
      "[90]\ttraining's auc: 0.999736\tvalid_1's auc: 0.99933\n",
      "[100]\ttraining's auc: 0.999798\tvalid_1's auc: 0.999368\n",
      "[110]\ttraining's auc: 0.999853\tvalid_1's auc: 0.999381\n",
      "[120]\ttraining's auc: 0.999892\tvalid_1's auc: 0.999402\n",
      "[130]\ttraining's auc: 0.999922\tvalid_1's auc: 0.999425\n",
      "[140]\ttraining's auc: 0.999943\tvalid_1's auc: 0.999431\n",
      "[150]\ttraining's auc: 0.999961\tvalid_1's auc: 0.999438\n",
      "[160]\ttraining's auc: 0.999972\tvalid_1's auc: 0.999439\n",
      "[170]\ttraining's auc: 0.999979\tvalid_1's auc: 0.999445\n",
      "[180]\ttraining's auc: 0.999986\tvalid_1's auc: 0.999454\n",
      "[190]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999456\n",
      "[200]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999463\n",
      "[210]\ttraining's auc: 0.999996\tvalid_1's auc: 0.99947\n",
      "[220]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999478\n",
      "[230]\ttraining's auc: 0.999999\tvalid_1's auc: 0.99948\n",
      "[240]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999489\n",
      "[250]\ttraining's auc: 1\tvalid_1's auc: 0.999486\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:04,983] Trial 37 finished with value: 0.9994885081732049 and parameters: {'num_leaves': 88, 'learning_rate': 0.07694434502355602, 'max_depth': 40, 'min_child_samples': 52, 'n_estimators': 736}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.990423\tvalid_1's auc: 0.99031\n",
      "[20]\ttraining's auc: 0.993619\tvalid_1's auc: 0.993661\n",
      "[30]\ttraining's auc: 0.995013\tvalid_1's auc: 0.995057\n",
      "[40]\ttraining's auc: 0.995716\tvalid_1's auc: 0.995683\n",
      "[50]\ttraining's auc: 0.996496\tvalid_1's auc: 0.996456\n",
      "[60]\ttraining's auc: 0.99739\tvalid_1's auc: 0.997351\n",
      "[70]\ttraining's auc: 0.997946\tvalid_1's auc: 0.997839\n",
      "[80]\ttraining's auc: 0.998385\tvalid_1's auc: 0.998138\n",
      "[90]\ttraining's auc: 0.998778\tvalid_1's auc: 0.998551\n",
      "[100]\ttraining's auc: 0.999003\tvalid_1's auc: 0.998753\n",
      "[110]\ttraining's auc: 0.999187\tvalid_1's auc: 0.998928\n",
      "[120]\ttraining's auc: 0.999335\tvalid_1's auc: 0.999061\n",
      "[130]\ttraining's auc: 0.999457\tvalid_1's auc: 0.999184\n",
      "[140]\ttraining's auc: 0.999555\tvalid_1's auc: 0.999271\n",
      "[150]\ttraining's auc: 0.99962\tvalid_1's auc: 0.999321\n",
      "[160]\ttraining's auc: 0.999673\tvalid_1's auc: 0.99935\n",
      "[170]\ttraining's auc: 0.999715\tvalid_1's auc: 0.999351\n",
      "[180]\ttraining's auc: 0.999749\tvalid_1's auc: 0.999376\n",
      "[190]\ttraining's auc: 0.999781\tvalid_1's auc: 0.999379\n",
      "[200]\ttraining's auc: 0.999804\tvalid_1's auc: 0.999392\n",
      "[210]\ttraining's auc: 0.999824\tvalid_1's auc: 0.999402\n",
      "[220]\ttraining's auc: 0.999844\tvalid_1's auc: 0.99941\n",
      "[230]\ttraining's auc: 0.999862\tvalid_1's auc: 0.999411\n",
      "[240]\ttraining's auc: 0.999878\tvalid_1's auc: 0.999415\n",
      "[250]\ttraining's auc: 0.99989\tvalid_1's auc: 0.999418\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's auc: 0.999889\tvalid_1's auc: 0.999418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:12,069] Trial 38 finished with value: 0.9994179860483285 and parameters: {'num_leaves': 63, 'learning_rate': 0.04822886595413538, 'max_depth': 40, 'min_child_samples': 51, 'n_estimators': 730}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.991898\tvalid_1's auc: 0.991712\n",
      "[20]\ttraining's auc: 0.993707\tvalid_1's auc: 0.993732\n",
      "[30]\ttraining's auc: 0.995108\tvalid_1's auc: 0.995007\n",
      "[40]\ttraining's auc: 0.996214\tvalid_1's auc: 0.996144\n",
      "[50]\ttraining's auc: 0.996752\tvalid_1's auc: 0.996626\n",
      "[60]\ttraining's auc: 0.997334\tvalid_1's auc: 0.997106\n",
      "[70]\ttraining's auc: 0.997838\tvalid_1's auc: 0.997567\n",
      "[80]\ttraining's auc: 0.998058\tvalid_1's auc: 0.997722\n",
      "[90]\ttraining's auc: 0.998393\tvalid_1's auc: 0.99809\n",
      "[100]\ttraining's auc: 0.998646\tvalid_1's auc: 0.998276\n",
      "[110]\ttraining's auc: 0.998856\tvalid_1's auc: 0.998494\n",
      "[120]\ttraining's auc: 0.999051\tvalid_1's auc: 0.998573\n",
      "[130]\ttraining's auc: 0.999218\tvalid_1's auc: 0.998693\n",
      "[140]\ttraining's auc: 0.999353\tvalid_1's auc: 0.998811\n",
      "[150]\ttraining's auc: 0.99947\tvalid_1's auc: 0.998893\n",
      "[160]\ttraining's auc: 0.999561\tvalid_1's auc: 0.998996\n",
      "[170]\ttraining's auc: 0.999629\tvalid_1's auc: 0.999046\n",
      "[180]\ttraining's auc: 0.999692\tvalid_1's auc: 0.999102\n",
      "[190]\ttraining's auc: 0.999743\tvalid_1's auc: 0.999163\n",
      "[200]\ttraining's auc: 0.999787\tvalid_1's auc: 0.999215\n",
      "[210]\ttraining's auc: 0.999825\tvalid_1's auc: 0.999247\n",
      "[220]\ttraining's auc: 0.999854\tvalid_1's auc: 0.999286\n",
      "[230]\ttraining's auc: 0.999881\tvalid_1's auc: 0.99931\n",
      "[240]\ttraining's auc: 0.999903\tvalid_1's auc: 0.999338\n",
      "[250]\ttraining's auc: 0.999918\tvalid_1's auc: 0.999346\n",
      "[260]\ttraining's auc: 0.999932\tvalid_1's auc: 0.999362\n",
      "[270]\ttraining's auc: 0.999944\tvalid_1's auc: 0.999376\n",
      "[280]\ttraining's auc: 0.999954\tvalid_1's auc: 0.999385\n",
      "[290]\ttraining's auc: 0.999964\tvalid_1's auc: 0.999392\n",
      "[300]\ttraining's auc: 0.99997\tvalid_1's auc: 0.999393\n",
      "[310]\ttraining's auc: 0.999976\tvalid_1's auc: 0.999399\n",
      "[320]\ttraining's auc: 0.99998\tvalid_1's auc: 0.999402\n",
      "Early stopping, best iteration is:\n",
      "[318]\ttraining's auc: 0.999979\tvalid_1's auc: 0.999403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:24,318] Trial 39 finished with value: 0.9994030470208893 and parameters: {'num_leaves': 135, 'learning_rate': 0.030393769493430034, 'max_depth': 50, 'min_child_samples': 62, 'n_estimators': 858}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992783\tvalid_1's auc: 0.992803\n",
      "[20]\ttraining's auc: 0.996212\tvalid_1's auc: 0.996261\n",
      "[30]\ttraining's auc: 0.997813\tvalid_1's auc: 0.997579\n",
      "[40]\ttraining's auc: 0.998588\tvalid_1's auc: 0.998267\n",
      "[50]\ttraining's auc: 0.999069\tvalid_1's auc: 0.998647\n",
      "[60]\ttraining's auc: 0.999473\tvalid_1's auc: 0.999044\n",
      "[70]\ttraining's auc: 0.99964\tvalid_1's auc: 0.999157\n",
      "[80]\ttraining's auc: 0.99976\tvalid_1's auc: 0.999245\n",
      "[90]\ttraining's auc: 0.999843\tvalid_1's auc: 0.999335\n",
      "[100]\ttraining's auc: 0.999894\tvalid_1's auc: 0.999376\n",
      "[110]\ttraining's auc: 0.999929\tvalid_1's auc: 0.99939\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:28,267] Trial 40 finished with value: 0.9993924147561654 and parameters: {'num_leaves': 111, 'learning_rate': 0.0810207481543091, 'max_depth': 45, 'min_child_samples': 76, 'n_estimators': 618}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995127\tvalid_1's auc: 0.995209\n",
      "[20]\ttraining's auc: 0.997202\tvalid_1's auc: 0.997102\n",
      "[30]\ttraining's auc: 0.998505\tvalid_1's auc: 0.998171\n",
      "[40]\ttraining's auc: 0.999128\tvalid_1's auc: 0.998674\n",
      "[50]\ttraining's auc: 0.99951\tvalid_1's auc: 0.999098\n",
      "[60]\ttraining's auc: 0.999702\tvalid_1's auc: 0.999285\n",
      "[70]\ttraining's auc: 0.9998\tvalid_1's auc: 0.999332\n",
      "[80]\ttraining's auc: 0.999876\tvalid_1's auc: 0.999354\n",
      "[90]\ttraining's auc: 0.999916\tvalid_1's auc: 0.999368\n",
      "[100]\ttraining's auc: 0.999946\tvalid_1's auc: 0.999374\n",
      "[110]\ttraining's auc: 0.999967\tvalid_1's auc: 0.9994\n",
      "[120]\ttraining's auc: 0.999979\tvalid_1's auc: 0.99941\n",
      "[130]\ttraining's auc: 0.999988\tvalid_1's auc: 0.999411\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's auc: 0.999982\tvalid_1's auc: 0.999417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:32,176] Trial 41 finished with value: 0.999417051578903 and parameters: {'num_leaves': 88, 'learning_rate': 0.11402803543595584, 'max_depth': 41, 'min_child_samples': 67, 'n_estimators': 390}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.991427\tvalid_1's auc: 0.991297\n",
      "[20]\ttraining's auc: 0.994952\tvalid_1's auc: 0.995043\n",
      "[30]\ttraining's auc: 0.996568\tvalid_1's auc: 0.996408\n",
      "[40]\ttraining's auc: 0.997667\tvalid_1's auc: 0.997543\n",
      "[50]\ttraining's auc: 0.998303\tvalid_1's auc: 0.998012\n",
      "[60]\ttraining's auc: 0.99879\tvalid_1's auc: 0.998402\n",
      "[70]\ttraining's auc: 0.999156\tvalid_1's auc: 0.998739\n",
      "[80]\ttraining's auc: 0.999401\tvalid_1's auc: 0.998999\n",
      "[90]\ttraining's auc: 0.999602\tvalid_1's auc: 0.999198\n",
      "[100]\ttraining's auc: 0.999701\tvalid_1's auc: 0.999291\n",
      "[110]\ttraining's auc: 0.999782\tvalid_1's auc: 0.999324\n",
      "[120]\ttraining's auc: 0.999833\tvalid_1's auc: 0.999342\n",
      "[130]\ttraining's auc: 0.999869\tvalid_1's auc: 0.999358\n",
      "[140]\ttraining's auc: 0.999892\tvalid_1's auc: 0.999376\n",
      "[150]\ttraining's auc: 0.999914\tvalid_1's auc: 0.999379\n",
      "[160]\ttraining's auc: 0.999931\tvalid_1's auc: 0.999392\n",
      "[170]\ttraining's auc: 0.999943\tvalid_1's auc: 0.9994\n",
      "[180]\ttraining's auc: 0.999956\tvalid_1's auc: 0.999406\n",
      "[190]\ttraining's auc: 0.999966\tvalid_1's auc: 0.999415\n",
      "[200]\ttraining's auc: 0.999974\tvalid_1's auc: 0.999419\n",
      "[210]\ttraining's auc: 0.99998\tvalid_1's auc: 0.999425\n",
      "[220]\ttraining's auc: 0.999985\tvalid_1's auc: 0.999434\n",
      "[230]\ttraining's auc: 0.999989\tvalid_1's auc: 0.999443\n",
      "[240]\ttraining's auc: 0.999991\tvalid_1's auc: 0.999449\n",
      "[250]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999453\n",
      "[260]\ttraining's auc: 0.999996\tvalid_1's auc: 0.999457\n",
      "[270]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999458\n",
      "[280]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999459\n",
      "[290]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999458\n",
      "Early stopping, best iteration is:\n",
      "[283]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:40,648] Trial 42 finished with value: 0.9994609966086465 and parameters: {'num_leaves': 73, 'learning_rate': 0.07048256033057086, 'max_depth': 31, 'min_child_samples': 16, 'n_estimators': 934}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995338\tvalid_1's auc: 0.995414\n",
      "[20]\ttraining's auc: 0.997772\tvalid_1's auc: 0.997537\n",
      "[30]\ttraining's auc: 0.999039\tvalid_1's auc: 0.998558\n",
      "[40]\ttraining's auc: 0.999541\tvalid_1's auc: 0.999022\n",
      "[50]\ttraining's auc: 0.999764\tvalid_1's auc: 0.999135\n",
      "[60]\ttraining's auc: 0.999877\tvalid_1's auc: 0.999291\n",
      "[70]\ttraining's auc: 0.999937\tvalid_1's auc: 0.999323\n",
      "[80]\ttraining's auc: 0.999966\tvalid_1's auc: 0.999334\n",
      "[90]\ttraining's auc: 0.999986\tvalid_1's auc: 0.999357\n",
      "[100]\ttraining's auc: 0.999994\tvalid_1's auc: 0.999374\n",
      "[110]\ttraining's auc: 0.999998\tvalid_1's auc: 0.999408\n",
      "[120]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999412\n",
      "[130]\ttraining's auc: 1\tvalid_1's auc: 0.999423\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's auc: 1\tvalid_1's auc: 0.999426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:45,373] Trial 43 finished with value: 0.9994264765233959 and parameters: {'num_leaves': 99, 'learning_rate': 0.13118849817539, 'max_depth': 38, 'min_child_samples': 22, 'n_estimators': 729}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.991266\tvalid_1's auc: 0.991016\n",
      "[20]\ttraining's auc: 0.994425\tvalid_1's auc: 0.994492\n",
      "[30]\ttraining's auc: 0.995349\tvalid_1's auc: 0.995382\n",
      "[40]\ttraining's auc: 0.996205\tvalid_1's auc: 0.996253\n",
      "[50]\ttraining's auc: 0.997405\tvalid_1's auc: 0.997237\n",
      "[60]\ttraining's auc: 0.998012\tvalid_1's auc: 0.99784\n",
      "[70]\ttraining's auc: 0.998457\tvalid_1's auc: 0.998198\n",
      "[80]\ttraining's auc: 0.998768\tvalid_1's auc: 0.998445\n",
      "[90]\ttraining's auc: 0.999146\tvalid_1's auc: 0.998819\n",
      "[100]\ttraining's auc: 0.999302\tvalid_1's auc: 0.998943\n",
      "[110]\ttraining's auc: 0.999484\tvalid_1's auc: 0.999116\n",
      "[120]\ttraining's auc: 0.99959\tvalid_1's auc: 0.999222\n",
      "[130]\ttraining's auc: 0.999669\tvalid_1's auc: 0.999302\n",
      "[140]\ttraining's auc: 0.999725\tvalid_1's auc: 0.999326\n",
      "[150]\ttraining's auc: 0.999771\tvalid_1's auc: 0.999359\n",
      "[160]\ttraining's auc: 0.999802\tvalid_1's auc: 0.999384\n",
      "[170]\ttraining's auc: 0.999836\tvalid_1's auc: 0.999398\n",
      "[180]\ttraining's auc: 0.999865\tvalid_1's auc: 0.999404\n",
      "[190]\ttraining's auc: 0.999887\tvalid_1's auc: 0.999407\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's auc: 0.999881\tvalid_1's auc: 0.999409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:52,077] Trial 44 finished with value: 0.9994088696214133 and parameters: {'num_leaves': 81, 'learning_rate': 0.05258127530047001, 'max_depth': 27, 'min_child_samples': 85, 'n_estimators': 654}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.993112\tvalid_1's auc: 0.99304\n",
      "[20]\ttraining's auc: 0.995053\tvalid_1's auc: 0.995208\n",
      "[30]\ttraining's auc: 0.996553\tvalid_1's auc: 0.996625\n",
      "[40]\ttraining's auc: 0.99767\tvalid_1's auc: 0.997587\n",
      "[50]\ttraining's auc: 0.998503\tvalid_1's auc: 0.998401\n",
      "[60]\ttraining's auc: 0.998926\tvalid_1's auc: 0.99878\n",
      "[70]\ttraining's auc: 0.999255\tvalid_1's auc: 0.999066\n",
      "[80]\ttraining's auc: 0.999465\tvalid_1's auc: 0.999221\n",
      "[90]\ttraining's auc: 0.999586\tvalid_1's auc: 0.99932\n",
      "[100]\ttraining's auc: 0.99966\tvalid_1's auc: 0.999352\n",
      "[110]\ttraining's auc: 0.999717\tvalid_1's auc: 0.999379\n",
      "[120]\ttraining's auc: 0.999767\tvalid_1's auc: 0.999393\n",
      "[130]\ttraining's auc: 0.999805\tvalid_1's auc: 0.999394\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's auc: 0.999789\tvalid_1's auc: 0.999395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:40:55,694] Trial 45 finished with value: 0.9993949274802505 and parameters: {'num_leaves': 54, 'learning_rate': 0.0882343935762713, 'max_depth': 35, 'min_child_samples': 58, 'n_estimators': 345}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.992482\tvalid_1's auc: 0.992511\n",
      "[20]\ttraining's auc: 0.995785\tvalid_1's auc: 0.99592\n",
      "[30]\ttraining's auc: 0.99734\tvalid_1's auc: 0.997178\n",
      "[40]\ttraining's auc: 0.998144\tvalid_1's auc: 0.998005\n",
      "[50]\ttraining's auc: 0.998707\tvalid_1's auc: 0.998418\n",
      "[60]\ttraining's auc: 0.999104\tvalid_1's auc: 0.998751\n",
      "[70]\ttraining's auc: 0.999337\tvalid_1's auc: 0.998923\n",
      "[80]\ttraining's auc: 0.999523\tvalid_1's auc: 0.999061\n",
      "[90]\ttraining's auc: 0.999646\tvalid_1's auc: 0.999169\n",
      "[100]\ttraining's auc: 0.999741\tvalid_1's auc: 0.999254\n",
      "[110]\ttraining's auc: 0.999806\tvalid_1's auc: 0.999305\n",
      "[120]\ttraining's auc: 0.999858\tvalid_1's auc: 0.999327\n",
      "[130]\ttraining's auc: 0.999892\tvalid_1's auc: 0.999342\n",
      "[140]\ttraining's auc: 0.999922\tvalid_1's auc: 0.999356\n",
      "[150]\ttraining's auc: 0.999943\tvalid_1's auc: 0.999356\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's auc: 0.999924\tvalid_1's auc: 0.999357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:41:00,682] Trial 46 finished with value: 0.999357423869525 and parameters: {'num_leaves': 105, 'learning_rate': 0.07524300926919575, 'max_depth': 12, 'min_child_samples': 65, 'n_estimators': 587}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.995137\tvalid_1's auc: 0.994968\n",
      "[20]\ttraining's auc: 0.997824\tvalid_1's auc: 0.997563\n",
      "[30]\ttraining's auc: 0.998821\tvalid_1's auc: 0.998524\n",
      "[40]\ttraining's auc: 0.999412\tvalid_1's auc: 0.998915\n",
      "[50]\ttraining's auc: 0.999687\tvalid_1's auc: 0.999174\n",
      "[60]\ttraining's auc: 0.999838\tvalid_1's auc: 0.999278\n",
      "[70]\ttraining's auc: 0.999915\tvalid_1's auc: 0.999349\n",
      "[80]\ttraining's auc: 0.99996\tvalid_1's auc: 0.999371\n",
      "[90]\ttraining's auc: 0.999983\tvalid_1's auc: 0.999377\n",
      "[100]\ttraining's auc: 0.999992\tvalid_1's auc: 0.999393\n",
      "[110]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999412\n",
      "[120]\ttraining's auc: 0.999999\tvalid_1's auc: 0.999409\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's auc: 0.999997\tvalid_1's auc: 0.999418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:41:05,325] Trial 47 finished with value: 0.999418290999229 and parameters: {'num_leaves': 119, 'learning_rate': 0.11363533175123751, 'max_depth': 46, 'min_child_samples': 47, 'n_estimators': 786}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.987442\tvalid_1's auc: 0.987854\n",
      "[20]\ttraining's auc: 0.991953\tvalid_1's auc: 0.992249\n",
      "[30]\ttraining's auc: 0.994201\tvalid_1's auc: 0.994459\n",
      "[40]\ttraining's auc: 0.996082\tvalid_1's auc: 0.996166\n",
      "[50]\ttraining's auc: 0.997297\tvalid_1's auc: 0.99732\n",
      "[60]\ttraining's auc: 0.997957\tvalid_1's auc: 0.997953\n",
      "[70]\ttraining's auc: 0.99835\tvalid_1's auc: 0.998309\n",
      "[80]\ttraining's auc: 0.998715\tvalid_1's auc: 0.998652\n",
      "[90]\ttraining's auc: 0.998957\tvalid_1's auc: 0.998862\n",
      "[100]\ttraining's auc: 0.99908\tvalid_1's auc: 0.998969\n",
      "[110]\ttraining's auc: 0.9992\tvalid_1's auc: 0.999077\n",
      "[120]\ttraining's auc: 0.999311\tvalid_1's auc: 0.999178\n",
      "[130]\ttraining's auc: 0.999372\tvalid_1's auc: 0.999225\n",
      "[140]\ttraining's auc: 0.999459\tvalid_1's auc: 0.99928\n",
      "[150]\ttraining's auc: 0.999505\tvalid_1's auc: 0.999312\n",
      "[160]\ttraining's auc: 0.999543\tvalid_1's auc: 0.999328\n",
      "[170]\ttraining's auc: 0.999582\tvalid_1's auc: 0.999356\n",
      "[180]\ttraining's auc: 0.999615\tvalid_1's auc: 0.999361\n",
      "[190]\ttraining's auc: 0.999645\tvalid_1's auc: 0.999368\n",
      "[200]\ttraining's auc: 0.999682\tvalid_1's auc: 0.999384\n",
      "[210]\ttraining's auc: 0.999708\tvalid_1's auc: 0.999396\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[218]\ttraining's auc: 0.999723\tvalid_1's auc: 0.999402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:41:10,317] Trial 48 finished with value: 0.9994021268181725 and parameters: {'num_leaves': 20, 'learning_rate': 0.0966244345442103, 'max_depth': 42, 'min_child_samples': 55, 'n_estimators': 218}. Best is trial 26 with value: 0.9994909941472111.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33750, number of negative: 262812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 296562, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113804 -> initscore=-2.052459\n",
      "[LightGBM] [Info] Start training from score -2.052459\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.989012\tvalid_1's auc: 0.989047\n",
      "[20]\ttraining's auc: 0.991602\tvalid_1's auc: 0.991531\n",
      "[30]\ttraining's auc: 0.992388\tvalid_1's auc: 0.992417\n",
      "[40]\ttraining's auc: 0.994762\tvalid_1's auc: 0.994772\n",
      "[50]\ttraining's auc: 0.995059\tvalid_1's auc: 0.995133\n",
      "[60]\ttraining's auc: 0.995701\tvalid_1's auc: 0.995758\n",
      "[70]\ttraining's auc: 0.995963\tvalid_1's auc: 0.996052\n",
      "[80]\ttraining's auc: 0.996218\tvalid_1's auc: 0.996268\n",
      "[90]\ttraining's auc: 0.997059\tvalid_1's auc: 0.996942\n",
      "[100]\ttraining's auc: 0.997483\tvalid_1's auc: 0.997273\n",
      "[110]\ttraining's auc: 0.997857\tvalid_1's auc: 0.997628\n",
      "[120]\ttraining's auc: 0.99811\tvalid_1's auc: 0.997902\n",
      "[130]\ttraining's auc: 0.998328\tvalid_1's auc: 0.998096\n",
      "[140]\ttraining's auc: 0.998516\tvalid_1's auc: 0.99821\n",
      "[150]\ttraining's auc: 0.998686\tvalid_1's auc: 0.998349\n",
      "[160]\ttraining's auc: 0.998806\tvalid_1's auc: 0.998437\n",
      "[170]\ttraining's auc: 0.998949\tvalid_1's auc: 0.998562\n",
      "[180]\ttraining's auc: 0.999072\tvalid_1's auc: 0.998675\n",
      "[190]\ttraining's auc: 0.999185\tvalid_1's auc: 0.998789\n",
      "[200]\ttraining's auc: 0.999293\tvalid_1's auc: 0.998891\n",
      "[210]\ttraining's auc: 0.999369\tvalid_1's auc: 0.998958\n",
      "[220]\ttraining's auc: 0.999447\tvalid_1's auc: 0.999037\n",
      "[230]\ttraining's auc: 0.999511\tvalid_1's auc: 0.999097\n",
      "[240]\ttraining's auc: 0.999566\tvalid_1's auc: 0.999138\n",
      "[250]\ttraining's auc: 0.999606\tvalid_1's auc: 0.999168\n",
      "[260]\ttraining's auc: 0.999654\tvalid_1's auc: 0.999236\n",
      "[270]\ttraining's auc: 0.999688\tvalid_1's auc: 0.999267\n",
      "[280]\ttraining's auc: 0.99972\tvalid_1's auc: 0.999293\n",
      "[290]\ttraining's auc: 0.999746\tvalid_1's auc: 0.999307\n",
      "[300]\ttraining's auc: 0.999767\tvalid_1's auc: 0.999319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[303]\ttraining's auc: 0.999773\tvalid_1's auc: 0.999326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:41:20,324] Trial 49 finished with value: 0.999325890876427 and parameters: {'num_leaves': 91, 'learning_rate': 0.024942149920402754, 'max_depth': 38, 'min_child_samples': 79, 'n_estimators': 303}. Best is trial 26 with value: 0.9994909941472111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_leaves': 84, 'learning_rate': 0.10168818622107392, 'max_depth': 40, 'min_child_samples': 10, 'n_estimators': 533}\n",
      "[LightGBM] [Info] Number of positive: 42299, number of negative: 328404\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4236\n",
      "[LightGBM] [Info] Number of data points in the train set: 370703, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.114105 -> initscore=-2.049481\n",
      "[LightGBM] [Info] Start training from score -2.049481\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.10168818622107392, max_depth=40,\n",
       "               min_child_samples=10, n_estimators=533, num_leaves=84,\n",
       "               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.10168818622107392, max_depth=40,\n",
       "               min_child_samples=10, n_estimators=533, num_leaves=84,\n",
       "               random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.10168818622107392, max_depth=40,\n",
       "               min_child_samples=10, n_estimators=533, num_leaves=84,\n",
       "               random_state=42)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "\n",
    "# Split training data for hyperparameter optimization\n",
    "X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Create LightGBM dataset\n",
    "    train_data = lgb.Dataset(X_train_opt, label=y_train_opt)\n",
    "    valid_data = lgb.Dataset(X_val_opt, label=y_val_opt, reference=train_data)\n",
    "\n",
    "    # Train the model with callbacks\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=10),  # Early stopping callback\n",
    "            log_evaluation(10)                  # Log progress every 10 rounds\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val_opt, num_iteration=model.best_iteration)\n",
    "    return roc_auc_score(y_val_opt, y_pred)\n",
    "\n",
    "# Optimize hyperparameters\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "\n",
    "# Train the final model with best parameters\n",
    "final_model = lgb.LGBMClassifier(**study.best_params, random_state=42)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5deec02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Threshold Optimization\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_val_pred_prob = model.predict_proba(X_val_opt)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_val_opt, y_val_pred_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(\"Optimal Threshold:\", optimal_threshold)\n",
    "\n",
    "# Apply this threshold to predictions\n",
    "test_probabilities = model.predict_proba(test_features)[:, 1]\n",
    "test_predictions = (test_probabilities >= optimal_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning test features with training features...\n",
      "Generating predictions on the test dataset...\n",
      "Creating submission file...\n",
      "Submission file saved as 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Ensure test features are preprocessed and aligned with training features\n",
    "print(\"Aligning test features with training features...\")\n",
    "missing_in_test = set(X_train.columns) - set(test_features.columns)\n",
    "for col in missing_in_test:\n",
    "    print(f\"Adding missing column '{col}' to test_features with default value 0.\")\n",
    "    test_features[col] = 0\n",
    "\n",
    "extra_in_test = set(test_features.columns) - set(X_train.columns)\n",
    "if extra_in_test:\n",
    "    print(f\"Removing extra columns from test_features: {extra_in_test}\")\n",
    "    test_features = test_features.drop(columns=list(extra_in_test))\n",
    "\n",
    "# Ensure test_features columns are in the same order as X_train\n",
    "test_features = test_features[X_train.columns]\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "print(\"Generating predictions on the test dataset...\")\n",
    "test_probabilities = final_model.predict_proba(test_features)[:, 1]\n",
    "threshold = 0.5  # Adjust threshold if necessary\n",
    "test_predictions = (test_probabilities >= threshold).astype(int)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "print(\"Creating submission file...\")\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],  # Ensure 'id' column exists in test_df\n",
    "    'is_fraud': test_predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_file_name = \"submission.csv\"\n",
    "submission.to_csv(submission_file_name, index=False)\n",
    "print(f\"Submission file saved as '{submission_file_name}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
